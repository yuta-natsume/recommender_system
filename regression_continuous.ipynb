{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9317ed52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from multiprocessing import Pool\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import seaborn as sn\n",
    "from pandas.io.parsers.readers import read_csv\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from pdb import set_trace\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from scipy.spatial.distance import cdist\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "12eade1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId\n",
       "414    414\n",
       "599    599\n",
       "474    474\n",
       "448    448\n",
       "274    274\n",
       "      ... \n",
       "524    524\n",
       "52      52\n",
       "268    268\n",
       "369    369\n",
       "314    314\n",
       "Name: userId, Length: 194, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_reviewers_df = pd.read_csv(\"/home/grigriko/general_model/general_modeluser_top_reviewers.csv\")\n",
    "top_reviewers_df.head()\n",
    "subj_idx = top_reviewers_df['userId'][:200].astype(str)\n",
    "subj_idx.index = subj_idx\n",
    "subj_idx = subj_idx.drop(['434', '570', '331', '230', '141', '475'])\n",
    "subj_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "300247b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_best_youdensJ = pd.read_csv(\"/home/grigriko/selected_seed3_1e-4/2nd_lr_1e-05/youdensJ/test/test_best_youdensJ.csv\")\n",
    "test_best_youdensJ.index = test_best_youdensJ['id'].astype(str)\n",
    "test_best_youdensJ = test_best_youdensJ.drop(['434', '570', '331', '230', '141', '475'])\n",
    "for i in range(len(test_best_youdensJ)):\n",
    "    selected_df = test_best_youdensJ.drop(test_best_youdensJ.query('youdensJ < 1.1').index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23ac0c56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[474,\n",
       " 610,\n",
       " 380,\n",
       " 249,\n",
       " 387,\n",
       " 603,\n",
       " 232,\n",
       " 305,\n",
       " 111,\n",
       " 217,\n",
       " 28,\n",
       " 534,\n",
       " 89,\n",
       " 64,\n",
       " 561,\n",
       " 18,\n",
       " 381,\n",
       " 368,\n",
       " 292,\n",
       " 21,\n",
       " 42,\n",
       " 294,\n",
       " 160,\n",
       " 580,\n",
       " 596,\n",
       " 202,\n",
       " 514,\n",
       " 391,\n",
       " 567,\n",
       " 339,\n",
       " 62,\n",
       " 199,\n",
       " 132,\n",
       " 313,\n",
       " 6,\n",
       " 425,\n",
       " 352,\n",
       " 382,\n",
       " 239,\n",
       " 365,\n",
       " 104,\n",
       " 63,\n",
       " 290,\n",
       " 495,\n",
       " 432,\n",
       " 330,\n",
       " 20,\n",
       " 594,\n",
       " 1,\n",
       " 82,\n",
       " 312,\n",
       " 605,\n",
       " 4,\n",
       " 119,\n",
       " 586,\n",
       " 234,\n",
       " 280,\n",
       " 607,\n",
       " 195,\n",
       " 266,\n",
       " 279,\n",
       " 167,\n",
       " 80,\n",
       " 587,\n",
       " 346,\n",
       " 265,\n",
       " 564,\n",
       " 33,\n",
       " 419,\n",
       " 7,\n",
       " 113,\n",
       " 100,\n",
       " 408,\n",
       " 47,\n",
       " 559,\n",
       " 10,\n",
       " 210,\n",
       " 464,\n",
       " 424,\n",
       " 602,\n",
       " 184,\n",
       " 268]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_user = selected_df['id']\n",
    "selected_user = selected_user.values.tolist()\n",
    "selected_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf51dd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_true_train = pd.read_csv(\"/home/grigriko/collaborative_filtering/selected_seed3/rest_true_train.csv\")\n",
    "all_true_train = pd.read_csv(\"/home/grigriko/collaborative_filtering/selected_seed3/all_true_train.csv\")\n",
    "all_true_test = pd.read_csv(\"/home/grigriko/collaborative_filtering/selected_seed3/all_true_test.csv\")\n",
    "all_true_valid = pd.read_csv(\"/home/grigriko/collaborative_filtering/selected_seed3/all_true_valid.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec8468cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>474</th>\n",
       "      <th>610</th>\n",
       "      <th>380</th>\n",
       "      <th>249</th>\n",
       "      <th>387</th>\n",
       "      <th>603</th>\n",
       "      <th>232</th>\n",
       "      <th>305</th>\n",
       "      <th>111</th>\n",
       "      <th>217</th>\n",
       "      <th>...</th>\n",
       "      <th>408</th>\n",
       "      <th>47</th>\n",
       "      <th>559</th>\n",
       "      <th>10</th>\n",
       "      <th>210</th>\n",
       "      <th>464</th>\n",
       "      <th>424</th>\n",
       "      <th>602</th>\n",
       "      <th>184</th>\n",
       "      <th>268</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.470148</td>\n",
       "      <td>8.073364</td>\n",
       "      <td>1.615161</td>\n",
       "      <td>10.827365</td>\n",
       "      <td>5.237511</td>\n",
       "      <td>2.958460</td>\n",
       "      <td>6.985659</td>\n",
       "      <td>8.775525</td>\n",
       "      <td>3.413839</td>\n",
       "      <td>0.720459</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.685812</td>\n",
       "      <td>2.603707</td>\n",
       "      <td>7.307000</td>\n",
       "      <td>6.828767</td>\n",
       "      <td>-8.645020</td>\n",
       "      <td>3.783793</td>\n",
       "      <td>-5.610519</td>\n",
       "      <td>6.725391</td>\n",
       "      <td>-10.230178</td>\n",
       "      <td>1.975236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.333591</td>\n",
       "      <td>2.153704</td>\n",
       "      <td>1.404535</td>\n",
       "      <td>1.891237</td>\n",
       "      <td>2.084127</td>\n",
       "      <td>-1.164362</td>\n",
       "      <td>0.766260</td>\n",
       "      <td>4.819980</td>\n",
       "      <td>0.355033</td>\n",
       "      <td>-3.242041</td>\n",
       "      <td>...</td>\n",
       "      <td>4.102377</td>\n",
       "      <td>3.170535</td>\n",
       "      <td>8.477814</td>\n",
       "      <td>-4.589009</td>\n",
       "      <td>-5.941176</td>\n",
       "      <td>3.518296</td>\n",
       "      <td>4.544995</td>\n",
       "      <td>6.776342</td>\n",
       "      <td>-7.641806</td>\n",
       "      <td>-2.762755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.687478</td>\n",
       "      <td>1.645324</td>\n",
       "      <td>-1.021170</td>\n",
       "      <td>0.818394</td>\n",
       "      <td>0.523362</td>\n",
       "      <td>-1.550715</td>\n",
       "      <td>0.152661</td>\n",
       "      <td>3.912056</td>\n",
       "      <td>-3.586549</td>\n",
       "      <td>5.600469</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.457685</td>\n",
       "      <td>-4.865715</td>\n",
       "      <td>7.200885</td>\n",
       "      <td>4.307720</td>\n",
       "      <td>3.462408</td>\n",
       "      <td>4.946462</td>\n",
       "      <td>3.510829</td>\n",
       "      <td>7.019444</td>\n",
       "      <td>-6.230763</td>\n",
       "      <td>-4.962788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.181397</td>\n",
       "      <td>0.705832</td>\n",
       "      <td>0.393751</td>\n",
       "      <td>1.733115</td>\n",
       "      <td>2.043169</td>\n",
       "      <td>0.160697</td>\n",
       "      <td>-2.211642</td>\n",
       "      <td>5.615347</td>\n",
       "      <td>1.106959</td>\n",
       "      <td>-3.808692</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.075878</td>\n",
       "      <td>2.374058</td>\n",
       "      <td>-7.849245</td>\n",
       "      <td>-5.304899</td>\n",
       "      <td>-6.653227</td>\n",
       "      <td>3.987716</td>\n",
       "      <td>3.239662</td>\n",
       "      <td>6.822750</td>\n",
       "      <td>-8.586972</td>\n",
       "      <td>-3.958260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.981762</td>\n",
       "      <td>12.335753</td>\n",
       "      <td>10.133099</td>\n",
       "      <td>13.755224</td>\n",
       "      <td>6.316472</td>\n",
       "      <td>2.427318</td>\n",
       "      <td>11.894456</td>\n",
       "      <td>11.189675</td>\n",
       "      <td>10.873768</td>\n",
       "      <td>5.928204</td>\n",
       "      <td>...</td>\n",
       "      <td>6.708402</td>\n",
       "      <td>-4.556232</td>\n",
       "      <td>-10.108963</td>\n",
       "      <td>7.652485</td>\n",
       "      <td>8.418906</td>\n",
       "      <td>6.159146</td>\n",
       "      <td>5.311392</td>\n",
       "      <td>-8.489306</td>\n",
       "      <td>-6.303382</td>\n",
       "      <td>-1.145474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>-0.584895</td>\n",
       "      <td>2.564359</td>\n",
       "      <td>-0.643591</td>\n",
       "      <td>1.063417</td>\n",
       "      <td>-1.750576</td>\n",
       "      <td>-1.608552</td>\n",
       "      <td>-1.902109</td>\n",
       "      <td>-3.774369</td>\n",
       "      <td>2.768858</td>\n",
       "      <td>-2.797375</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.745848</td>\n",
       "      <td>-4.532735</td>\n",
       "      <td>-6.601830</td>\n",
       "      <td>-4.383046</td>\n",
       "      <td>-6.339805</td>\n",
       "      <td>-4.375668</td>\n",
       "      <td>-4.376466</td>\n",
       "      <td>-6.118385</td>\n",
       "      <td>-7.274575</td>\n",
       "      <td>-3.754389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>-0.643417</td>\n",
       "      <td>-1.376117</td>\n",
       "      <td>-1.115946</td>\n",
       "      <td>0.220254</td>\n",
       "      <td>-1.872958</td>\n",
       "      <td>-2.006505</td>\n",
       "      <td>-2.595420</td>\n",
       "      <td>-3.459942</td>\n",
       "      <td>-3.015983</td>\n",
       "      <td>-3.830279</td>\n",
       "      <td>...</td>\n",
       "      <td>4.275549</td>\n",
       "      <td>-4.511329</td>\n",
       "      <td>-7.527024</td>\n",
       "      <td>-5.775187</td>\n",
       "      <td>-6.285461</td>\n",
       "      <td>-5.185131</td>\n",
       "      <td>-4.655141</td>\n",
       "      <td>-5.680228</td>\n",
       "      <td>-6.948728</td>\n",
       "      <td>-4.722132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>-0.678423</td>\n",
       "      <td>2.586876</td>\n",
       "      <td>1.881888</td>\n",
       "      <td>1.130497</td>\n",
       "      <td>-1.562579</td>\n",
       "      <td>-1.410933</td>\n",
       "      <td>-2.519826</td>\n",
       "      <td>-3.764510</td>\n",
       "      <td>3.607828</td>\n",
       "      <td>-4.309398</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.644498</td>\n",
       "      <td>-4.901551</td>\n",
       "      <td>-8.373261</td>\n",
       "      <td>-5.668779</td>\n",
       "      <td>-6.598558</td>\n",
       "      <td>-4.422167</td>\n",
       "      <td>-4.528232</td>\n",
       "      <td>-6.450583</td>\n",
       "      <td>-6.399121</td>\n",
       "      <td>-4.637159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>-0.677587</td>\n",
       "      <td>0.951504</td>\n",
       "      <td>-1.038386</td>\n",
       "      <td>-0.970879</td>\n",
       "      <td>-2.122784</td>\n",
       "      <td>-1.904010</td>\n",
       "      <td>-2.370738</td>\n",
       "      <td>6.365950</td>\n",
       "      <td>-3.385257</td>\n",
       "      <td>-3.466419</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.643372</td>\n",
       "      <td>-3.611502</td>\n",
       "      <td>-8.110580</td>\n",
       "      <td>-5.395319</td>\n",
       "      <td>-5.488996</td>\n",
       "      <td>-3.884645</td>\n",
       "      <td>-6.414458</td>\n",
       "      <td>-6.280785</td>\n",
       "      <td>-6.926425</td>\n",
       "      <td>-4.229196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>-0.718217</td>\n",
       "      <td>0.938572</td>\n",
       "      <td>-0.396092</td>\n",
       "      <td>2.219499</td>\n",
       "      <td>-2.094026</td>\n",
       "      <td>-2.089879</td>\n",
       "      <td>-2.227180</td>\n",
       "      <td>-3.588141</td>\n",
       "      <td>3.752510</td>\n",
       "      <td>-4.471001</td>\n",
       "      <td>...</td>\n",
       "      <td>3.721584</td>\n",
       "      <td>-3.784519</td>\n",
       "      <td>-8.112313</td>\n",
       "      <td>-6.063077</td>\n",
       "      <td>-5.585952</td>\n",
       "      <td>-4.297566</td>\n",
       "      <td>2.544791</td>\n",
       "      <td>-6.044182</td>\n",
       "      <td>-6.880417</td>\n",
       "      <td>-4.002408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            474        610        380        249       387       603  \\\n",
       "0     13.470148   8.073364   1.615161  10.827365  5.237511  2.958460   \n",
       "1     -0.333591   2.153704   1.404535   1.891237  2.084127 -1.164362   \n",
       "2     -0.687478   1.645324  -1.021170   0.818394  0.523362 -1.550715   \n",
       "3      1.181397   0.705832   0.393751   1.733115  2.043169  0.160697   \n",
       "4      6.981762  12.335753  10.133099  13.755224  6.316472  2.427318   \n",
       "...         ...        ...        ...        ...       ...       ...   \n",
       "1995  -0.584895   2.564359  -0.643591   1.063417 -1.750576 -1.608552   \n",
       "1996  -0.643417  -1.376117  -1.115946   0.220254 -1.872958 -2.006505   \n",
       "1997  -0.678423   2.586876   1.881888   1.130497 -1.562579 -1.410933   \n",
       "1998  -0.677587   0.951504  -1.038386  -0.970879 -2.122784 -1.904010   \n",
       "1999  -0.718217   0.938572  -0.396092   2.219499 -2.094026 -2.089879   \n",
       "\n",
       "            232        305        111       217  ...       408       47   \\\n",
       "0      6.985659   8.775525   3.413839  0.720459  ... -5.685812  2.603707   \n",
       "1      0.766260   4.819980   0.355033 -3.242041  ...  4.102377  3.170535   \n",
       "2      0.152661   3.912056  -3.586549  5.600469  ... -5.457685 -4.865715   \n",
       "3     -2.211642   5.615347   1.106959 -3.808692  ... -5.075878  2.374058   \n",
       "4     11.894456  11.189675  10.873768  5.928204  ...  6.708402 -4.556232   \n",
       "...         ...        ...        ...       ...  ...       ...       ...   \n",
       "1995  -1.902109  -3.774369   2.768858 -2.797375  ... -5.745848 -4.532735   \n",
       "1996  -2.595420  -3.459942  -3.015983 -3.830279  ...  4.275549 -4.511329   \n",
       "1997  -2.519826  -3.764510   3.607828 -4.309398  ... -4.644498 -4.901551   \n",
       "1998  -2.370738   6.365950  -3.385257 -3.466419  ... -4.643372 -3.611502   \n",
       "1999  -2.227180  -3.588141   3.752510 -4.471001  ...  3.721584 -3.784519   \n",
       "\n",
       "            559       10        210       464       424       602        184  \\\n",
       "0      7.307000  6.828767 -8.645020  3.783793 -5.610519  6.725391 -10.230178   \n",
       "1      8.477814 -4.589009 -5.941176  3.518296  4.544995  6.776342  -7.641806   \n",
       "2      7.200885  4.307720  3.462408  4.946462  3.510829  7.019444  -6.230763   \n",
       "3     -7.849245 -5.304899 -6.653227  3.987716  3.239662  6.822750  -8.586972   \n",
       "4    -10.108963  7.652485  8.418906  6.159146  5.311392 -8.489306  -6.303382   \n",
       "...         ...       ...       ...       ...       ...       ...        ...   \n",
       "1995  -6.601830 -4.383046 -6.339805 -4.375668 -4.376466 -6.118385  -7.274575   \n",
       "1996  -7.527024 -5.775187 -6.285461 -5.185131 -4.655141 -5.680228  -6.948728   \n",
       "1997  -8.373261 -5.668779 -6.598558 -4.422167 -4.528232 -6.450583  -6.399121   \n",
       "1998  -8.110580 -5.395319 -5.488996 -3.884645 -6.414458 -6.280785  -6.926425   \n",
       "1999  -8.112313 -6.063077 -5.585952 -4.297566  2.544791 -6.044182  -6.880417   \n",
       "\n",
       "           268  \n",
       "0     1.975236  \n",
       "1    -2.762755  \n",
       "2    -4.962788  \n",
       "3    -3.958260  \n",
       "4    -1.145474  \n",
       "...        ...  \n",
       "1995 -3.754389  \n",
       "1996 -4.722132  \n",
       "1997 -4.637159  \n",
       "1998 -4.229196  \n",
       "1999 -4.002408  \n",
       "\n",
       "[2000 rows x 82 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data for similarity\n",
    "train_continuous_df = pd.DataFrame()\n",
    "train_true_df = pd.DataFrame()\n",
    "for idx in selected_user:\n",
    "    train_summary = pd.read_csv(\"/home/grigriko/selected_seed3_1e-4/2nd_lr_1e-05/pred/pred_df_output_\" + str(idx) + \".csv\")\n",
    "    train_continuous_df[idx] = train_summary['pred_vec']\n",
    "    train_true_df[idx] = train_summary['test_vec']\n",
    "\n",
    "train_continuous_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2909b8da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>474</th>\n",
       "      <th>610</th>\n",
       "      <th>380</th>\n",
       "      <th>249</th>\n",
       "      <th>387</th>\n",
       "      <th>182</th>\n",
       "      <th>603</th>\n",
       "      <th>232</th>\n",
       "      <th>608</th>\n",
       "      <th>19</th>\n",
       "      <th>...</th>\n",
       "      <th>7</th>\n",
       "      <th>326</th>\n",
       "      <th>113</th>\n",
       "      <th>100</th>\n",
       "      <th>137</th>\n",
       "      <th>129</th>\n",
       "      <th>10</th>\n",
       "      <th>210</th>\n",
       "      <th>376</th>\n",
       "      <th>369</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.766769</td>\n",
       "      <td>0.609047</td>\n",
       "      <td>0.745579</td>\n",
       "      <td>0.814675</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.837234</td>\n",
       "      <td>0.725624</td>\n",
       "      <td>0.799495</td>\n",
       "      <td>0.753376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606897</td>\n",
       "      <td>0.829307</td>\n",
       "      <td>0.944209</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.599671</td>\n",
       "      <td>0.140327</td>\n",
       "      <td>0.918853</td>\n",
       "      <td>0.239660</td>\n",
       "      <td>0.846635</td>\n",
       "      <td>0.195692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.146941</td>\n",
       "      <td>0.292929</td>\n",
       "      <td>0.397107</td>\n",
       "      <td>0.423103</td>\n",
       "      <td>0.446861</td>\n",
       "      <td>0.368333</td>\n",
       "      <td>0.419738</td>\n",
       "      <td>0.603538</td>\n",
       "      <td>0.563191</td>\n",
       "      <td>0.387307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180045</td>\n",
       "      <td>0.834367</td>\n",
       "      <td>0.362394</td>\n",
       "      <td>0.273911</td>\n",
       "      <td>0.657242</td>\n",
       "      <td>0.236819</td>\n",
       "      <td>0.348691</td>\n",
       "      <td>0.308537</td>\n",
       "      <td>0.163621</td>\n",
       "      <td>0.284151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.011847</td>\n",
       "      <td>0.247090</td>\n",
       "      <td>0.227904</td>\n",
       "      <td>0.473789</td>\n",
       "      <td>0.473530</td>\n",
       "      <td>0.379249</td>\n",
       "      <td>0.383918</td>\n",
       "      <td>0.460113</td>\n",
       "      <td>0.490599</td>\n",
       "      <td>0.393809</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177665</td>\n",
       "      <td>0.392309</td>\n",
       "      <td>0.280963</td>\n",
       "      <td>0.791950</td>\n",
       "      <td>0.640826</td>\n",
       "      <td>0.186487</td>\n",
       "      <td>0.830674</td>\n",
       "      <td>0.786851</td>\n",
       "      <td>0.143109</td>\n",
       "      <td>0.245738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.219047</td>\n",
       "      <td>0.296734</td>\n",
       "      <td>0.359489</td>\n",
       "      <td>0.529458</td>\n",
       "      <td>0.486007</td>\n",
       "      <td>0.473534</td>\n",
       "      <td>0.567779</td>\n",
       "      <td>0.461329</td>\n",
       "      <td>0.539958</td>\n",
       "      <td>0.429441</td>\n",
       "      <td>...</td>\n",
       "      <td>0.504991</td>\n",
       "      <td>0.599008</td>\n",
       "      <td>0.845783</td>\n",
       "      <td>0.278629</td>\n",
       "      <td>0.599442</td>\n",
       "      <td>0.277799</td>\n",
       "      <td>0.321839</td>\n",
       "      <td>0.321882</td>\n",
       "      <td>0.169716</td>\n",
       "      <td>0.224977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.592956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.854950</td>\n",
       "      <td>0.905116</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.937380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214856</td>\n",
       "      <td>0.576241</td>\n",
       "      <td>0.174250</td>\n",
       "      <td>0.297125</td>\n",
       "      <td>0.871027</td>\n",
       "      <td>0.902810</td>\n",
       "      <td>0.782171</td>\n",
       "      <td>0.789569</td>\n",
       "      <td>0.862799</td>\n",
       "      <td>0.889446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.025664</td>\n",
       "      <td>0.385336</td>\n",
       "      <td>0.213553</td>\n",
       "      <td>0.527988</td>\n",
       "      <td>0.019286</td>\n",
       "      <td>0.056138</td>\n",
       "      <td>0.508343</td>\n",
       "      <td>0.481264</td>\n",
       "      <td>0.177435</td>\n",
       "      <td>0.396396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183059</td>\n",
       "      <td>0.484645</td>\n",
       "      <td>0.306246</td>\n",
       "      <td>0.281702</td>\n",
       "      <td>0.121901</td>\n",
       "      <td>0.254047</td>\n",
       "      <td>0.323537</td>\n",
       "      <td>0.286419</td>\n",
       "      <td>0.161778</td>\n",
       "      <td>0.190595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.011517</td>\n",
       "      <td>0.230750</td>\n",
       "      <td>0.190121</td>\n",
       "      <td>0.316640</td>\n",
       "      <td>0.061632</td>\n",
       "      <td>0.039619</td>\n",
       "      <td>0.376719</td>\n",
       "      <td>0.452603</td>\n",
       "      <td>0.188050</td>\n",
       "      <td>0.352770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145965</td>\n",
       "      <td>0.240425</td>\n",
       "      <td>0.289376</td>\n",
       "      <td>0.297456</td>\n",
       "      <td>0.145635</td>\n",
       "      <td>0.245976</td>\n",
       "      <td>0.285161</td>\n",
       "      <td>0.274162</td>\n",
       "      <td>0.159399</td>\n",
       "      <td>0.219674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.013060</td>\n",
       "      <td>0.390916</td>\n",
       "      <td>0.350171</td>\n",
       "      <td>0.472682</td>\n",
       "      <td>0.077817</td>\n",
       "      <td>0.053909</td>\n",
       "      <td>0.425840</td>\n",
       "      <td>0.466641</td>\n",
       "      <td>0.185814</td>\n",
       "      <td>0.422176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170599</td>\n",
       "      <td>0.214562</td>\n",
       "      <td>0.335204</td>\n",
       "      <td>0.238568</td>\n",
       "      <td>0.140452</td>\n",
       "      <td>0.231258</td>\n",
       "      <td>0.297037</td>\n",
       "      <td>0.167204</td>\n",
       "      <td>0.134723</td>\n",
       "      <td>0.181942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.013027</td>\n",
       "      <td>0.305911</td>\n",
       "      <td>0.199052</td>\n",
       "      <td>0.206835</td>\n",
       "      <td>0.068445</td>\n",
       "      <td>0.042618</td>\n",
       "      <td>0.373367</td>\n",
       "      <td>0.461579</td>\n",
       "      <td>0.174573</td>\n",
       "      <td>0.372344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190691</td>\n",
       "      <td>0.217121</td>\n",
       "      <td>0.233756</td>\n",
       "      <td>0.246957</td>\n",
       "      <td>0.103025</td>\n",
       "      <td>0.218705</td>\n",
       "      <td>0.264020</td>\n",
       "      <td>0.257471</td>\n",
       "      <td>0.143863</td>\n",
       "      <td>0.251573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.004905</td>\n",
       "      <td>0.319909</td>\n",
       "      <td>0.196701</td>\n",
       "      <td>0.448225</td>\n",
       "      <td>0.092968</td>\n",
       "      <td>0.045891</td>\n",
       "      <td>0.358329</td>\n",
       "      <td>0.452652</td>\n",
       "      <td>0.169423</td>\n",
       "      <td>0.378984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203450</td>\n",
       "      <td>0.217206</td>\n",
       "      <td>0.300132</td>\n",
       "      <td>0.235246</td>\n",
       "      <td>0.091087</td>\n",
       "      <td>0.256503</td>\n",
       "      <td>0.311446</td>\n",
       "      <td>0.300106</td>\n",
       "      <td>0.163888</td>\n",
       "      <td>0.252600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           474       610       380       249       387       182       603  \\\n",
       "0     1.000000  0.766769  0.609047  0.745579  0.814675  0.789474  0.837234   \n",
       "1     0.146941  0.292929  0.397107  0.423103  0.446861  0.368333  0.419738   \n",
       "2     0.011847  0.247090  0.227904  0.473789  0.473530  0.379249  0.383918   \n",
       "3     0.219047  0.296734  0.359489  0.529458  0.486007  0.473534  0.567779   \n",
       "4     0.592956  1.000000  1.000000  1.000000  1.000000  1.000000  0.854950   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1995  0.025664  0.385336  0.213553  0.527988  0.019286  0.056138  0.508343   \n",
       "1996  0.011517  0.230750  0.190121  0.316640  0.061632  0.039619  0.376719   \n",
       "1997  0.013060  0.390916  0.350171  0.472682  0.077817  0.053909  0.425840   \n",
       "1998  0.013027  0.305911  0.199052  0.206835  0.068445  0.042618  0.373367   \n",
       "1999  0.004905  0.319909  0.196701  0.448225  0.092968  0.045891  0.358329   \n",
       "\n",
       "           232       608       19   ...       7         326       113  \\\n",
       "0     0.725624  0.799495  0.753376  ...  0.606897  0.829307  0.944209   \n",
       "1     0.603538  0.563191  0.387307  ...  0.180045  0.834367  0.362394   \n",
       "2     0.460113  0.490599  0.393809  ...  0.177665  0.392309  0.280963   \n",
       "3     0.461329  0.539958  0.429441  ...  0.504991  0.599008  0.845783   \n",
       "4     0.905116  1.000000  0.937380  ...  0.214856  0.576241  0.174250   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1995  0.481264  0.177435  0.396396  ...  0.183059  0.484645  0.306246   \n",
       "1996  0.452603  0.188050  0.352770  ...  0.145965  0.240425  0.289376   \n",
       "1997  0.466641  0.185814  0.422176  ...  0.170599  0.214562  0.335204   \n",
       "1998  0.461579  0.174573  0.372344  ...  0.190691  0.217121  0.233756   \n",
       "1999  0.452652  0.169423  0.378984  ...  0.203450  0.217206  0.300132   \n",
       "\n",
       "           100       137       129       10        210       376       369  \n",
       "0     1.000000  0.599671  0.140327  0.918853  0.239660  0.846635  0.195692  \n",
       "1     0.273911  0.657242  0.236819  0.348691  0.308537  0.163621  0.284151  \n",
       "2     0.791950  0.640826  0.186487  0.830674  0.786851  0.143109  0.245738  \n",
       "3     0.278629  0.599442  0.277799  0.321839  0.321882  0.169716  0.224977  \n",
       "4     0.297125  0.871027  0.902810  0.782171  0.789569  0.862799  0.889446  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1995  0.281702  0.121901  0.254047  0.323537  0.286419  0.161778  0.190595  \n",
       "1996  0.297456  0.145635  0.245976  0.285161  0.274162  0.159399  0.219674  \n",
       "1997  0.238568  0.140452  0.231258  0.297037  0.167204  0.134723  0.181942  \n",
       "1998  0.246957  0.103025  0.218705  0.264020  0.257471  0.143863  0.251573  \n",
       "1999  0.235246  0.091087  0.256503  0.311446  0.300106  0.163888  0.252600  \n",
       "\n",
       "[2000 rows x 82 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_continuous_normed = pd.DataFrame()\n",
    "# for col in train_continuous_df.columns:\n",
    "#     min = train_continuous_df[col].min()\n",
    "#     max = train_continuous_df[col].max()\n",
    "#     train_continuous_normed[col] = train_continuous_df[col].apply(lambda x: (x-min) / (max - min))\n",
    "# train_continuous_normed                                                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "738ba078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>474</th>\n",
       "      <th>610</th>\n",
       "      <th>380</th>\n",
       "      <th>249</th>\n",
       "      <th>387</th>\n",
       "      <th>603</th>\n",
       "      <th>232</th>\n",
       "      <th>305</th>\n",
       "      <th>111</th>\n",
       "      <th>217</th>\n",
       "      <th>...</th>\n",
       "      <th>408</th>\n",
       "      <th>47</th>\n",
       "      <th>559</th>\n",
       "      <th>10</th>\n",
       "      <th>210</th>\n",
       "      <th>464</th>\n",
       "      <th>424</th>\n",
       "      <th>602</th>\n",
       "      <th>184</th>\n",
       "      <th>268</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.211690</td>\n",
       "      <td>-1.171585</td>\n",
       "      <td>-0.925138</td>\n",
       "      <td>-1.450670</td>\n",
       "      <td>-1.092379</td>\n",
       "      <td>-0.616587</td>\n",
       "      <td>-2.240844</td>\n",
       "      <td>-3.642152</td>\n",
       "      <td>-3.045418</td>\n",
       "      <td>-2.082806</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.221357</td>\n",
       "      <td>-4.736862</td>\n",
       "      <td>-7.145763</td>\n",
       "      <td>-4.686394</td>\n",
       "      <td>-6.376207</td>\n",
       "      <td>-4.718713</td>\n",
       "      <td>-3.837142</td>\n",
       "      <td>-5.098055</td>\n",
       "      <td>-6.615371</td>\n",
       "      <td>-3.494489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.133434</td>\n",
       "      <td>3.643634</td>\n",
       "      <td>-0.871082</td>\n",
       "      <td>-0.713372</td>\n",
       "      <td>0.559639</td>\n",
       "      <td>-0.740117</td>\n",
       "      <td>3.074211</td>\n",
       "      <td>3.864147</td>\n",
       "      <td>-0.848731</td>\n",
       "      <td>0.951730</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.522250</td>\n",
       "      <td>-2.843558</td>\n",
       "      <td>-1.386736</td>\n",
       "      <td>-3.607237</td>\n",
       "      <td>-2.620280</td>\n",
       "      <td>-1.531399</td>\n",
       "      <td>-1.628352</td>\n",
       "      <td>-4.333444</td>\n",
       "      <td>-5.644428</td>\n",
       "      <td>-1.784597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.332506</td>\n",
       "      <td>-0.611248</td>\n",
       "      <td>1.815270</td>\n",
       "      <td>-0.798200</td>\n",
       "      <td>0.257612</td>\n",
       "      <td>-0.937943</td>\n",
       "      <td>-1.009782</td>\n",
       "      <td>-2.228613</td>\n",
       "      <td>-2.627241</td>\n",
       "      <td>2.817279</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.112096</td>\n",
       "      <td>-3.834447</td>\n",
       "      <td>-5.906825</td>\n",
       "      <td>-4.846343</td>\n",
       "      <td>-4.970954</td>\n",
       "      <td>-4.154849</td>\n",
       "      <td>-3.095449</td>\n",
       "      <td>-5.035297</td>\n",
       "      <td>-7.080035</td>\n",
       "      <td>-2.908712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.468909</td>\n",
       "      <td>-1.050571</td>\n",
       "      <td>-0.982156</td>\n",
       "      <td>-1.743758</td>\n",
       "      <td>-1.299926</td>\n",
       "      <td>-1.083860</td>\n",
       "      <td>-2.245699</td>\n",
       "      <td>-3.546115</td>\n",
       "      <td>-3.819873</td>\n",
       "      <td>-1.148243</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.928733</td>\n",
       "      <td>-4.824050</td>\n",
       "      <td>-8.590173</td>\n",
       "      <td>-5.658017</td>\n",
       "      <td>-7.148934</td>\n",
       "      <td>-4.479245</td>\n",
       "      <td>-4.325623</td>\n",
       "      <td>-4.976818</td>\n",
       "      <td>-7.235293</td>\n",
       "      <td>-2.379287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.301689</td>\n",
       "      <td>-1.003750</td>\n",
       "      <td>-0.507712</td>\n",
       "      <td>-1.112822</td>\n",
       "      <td>-0.285598</td>\n",
       "      <td>-1.489955</td>\n",
       "      <td>-1.692030</td>\n",
       "      <td>-3.044380</td>\n",
       "      <td>-3.207813</td>\n",
       "      <td>-2.981938</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.774355</td>\n",
       "      <td>-3.830621</td>\n",
       "      <td>-7.278418</td>\n",
       "      <td>-5.184255</td>\n",
       "      <td>-6.954991</td>\n",
       "      <td>-4.763323</td>\n",
       "      <td>-4.439810</td>\n",
       "      <td>-5.881406</td>\n",
       "      <td>-8.004717</td>\n",
       "      <td>-4.863181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>-0.392038</td>\n",
       "      <td>0.351876</td>\n",
       "      <td>-0.432032</td>\n",
       "      <td>0.114498</td>\n",
       "      <td>-1.306625</td>\n",
       "      <td>-1.111173</td>\n",
       "      <td>-1.915079</td>\n",
       "      <td>1.056122</td>\n",
       "      <td>-2.675581</td>\n",
       "      <td>-0.692477</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.634108</td>\n",
       "      <td>1.027840</td>\n",
       "      <td>-7.139925</td>\n",
       "      <td>-4.734542</td>\n",
       "      <td>-5.951093</td>\n",
       "      <td>-2.467747</td>\n",
       "      <td>-2.825099</td>\n",
       "      <td>-5.854614</td>\n",
       "      <td>-5.811292</td>\n",
       "      <td>-2.049830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>-0.232667</td>\n",
       "      <td>-1.781542</td>\n",
       "      <td>-1.231595</td>\n",
       "      <td>-1.586003</td>\n",
       "      <td>-1.190971</td>\n",
       "      <td>-1.360417</td>\n",
       "      <td>-2.520275</td>\n",
       "      <td>-3.080211</td>\n",
       "      <td>-2.189613</td>\n",
       "      <td>-3.882350</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.338565</td>\n",
       "      <td>-4.610166</td>\n",
       "      <td>-9.073524</td>\n",
       "      <td>-6.186463</td>\n",
       "      <td>-6.666696</td>\n",
       "      <td>-5.512905</td>\n",
       "      <td>-4.706944</td>\n",
       "      <td>-6.450043</td>\n",
       "      <td>-8.598271</td>\n",
       "      <td>-4.921342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>-0.640632</td>\n",
       "      <td>-1.048574</td>\n",
       "      <td>-1.233104</td>\n",
       "      <td>-1.179785</td>\n",
       "      <td>-2.141739</td>\n",
       "      <td>-1.878563</td>\n",
       "      <td>-2.240835</td>\n",
       "      <td>-1.614200</td>\n",
       "      <td>-2.267794</td>\n",
       "      <td>-5.018567</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.109042</td>\n",
       "      <td>-3.481608</td>\n",
       "      <td>-8.051427</td>\n",
       "      <td>-5.371017</td>\n",
       "      <td>-6.167434</td>\n",
       "      <td>-4.866140</td>\n",
       "      <td>-5.933562</td>\n",
       "      <td>-5.950708</td>\n",
       "      <td>-5.725215</td>\n",
       "      <td>-4.516814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>-0.671378</td>\n",
       "      <td>-0.953768</td>\n",
       "      <td>-0.413315</td>\n",
       "      <td>-0.238094</td>\n",
       "      <td>-1.946312</td>\n",
       "      <td>-2.050528</td>\n",
       "      <td>-0.310033</td>\n",
       "      <td>-2.054919</td>\n",
       "      <td>-1.219164</td>\n",
       "      <td>-3.287626</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.547672</td>\n",
       "      <td>-4.293945</td>\n",
       "      <td>-7.015092</td>\n",
       "      <td>-5.465717</td>\n",
       "      <td>-2.947444</td>\n",
       "      <td>-3.871702</td>\n",
       "      <td>-4.691895</td>\n",
       "      <td>-6.265155</td>\n",
       "      <td>-4.414776</td>\n",
       "      <td>-3.036618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>-0.493062</td>\n",
       "      <td>-0.933745</td>\n",
       "      <td>-1.119927</td>\n",
       "      <td>-1.274721</td>\n",
       "      <td>-1.342646</td>\n",
       "      <td>-1.474143</td>\n",
       "      <td>-2.219864</td>\n",
       "      <td>-2.773711</td>\n",
       "      <td>-3.739665</td>\n",
       "      <td>-3.838202</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.356044</td>\n",
       "      <td>-4.338513</td>\n",
       "      <td>-7.183603</td>\n",
       "      <td>-5.877066</td>\n",
       "      <td>-6.523636</td>\n",
       "      <td>-4.800256</td>\n",
       "      <td>-4.452844</td>\n",
       "      <td>-5.873162</td>\n",
       "      <td>-7.251852</td>\n",
       "      <td>-3.685054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          474       610       380       249       387       603       232  \\\n",
       "0   -0.211690 -1.171585 -0.925138 -1.450670 -1.092379 -0.616587 -2.240844   \n",
       "1    0.133434  3.643634 -0.871082 -0.713372  0.559639 -0.740117  3.074211   \n",
       "2    1.332506 -0.611248  1.815270 -0.798200  0.257612 -0.937943 -1.009782   \n",
       "3   -0.468909 -1.050571 -0.982156 -1.743758 -1.299926 -1.083860 -2.245699   \n",
       "4   -0.301689 -1.003750 -0.507712 -1.112822 -0.285598 -1.489955 -1.692030   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "494 -0.392038  0.351876 -0.432032  0.114498 -1.306625 -1.111173 -1.915079   \n",
       "495 -0.232667 -1.781542 -1.231595 -1.586003 -1.190971 -1.360417 -2.520275   \n",
       "496 -0.640632 -1.048574 -1.233104 -1.179785 -2.141739 -1.878563 -2.240835   \n",
       "497 -0.671378 -0.953768 -0.413315 -0.238094 -1.946312 -2.050528 -0.310033   \n",
       "498 -0.493062 -0.933745 -1.119927 -1.274721 -1.342646 -1.474143 -2.219864   \n",
       "\n",
       "          305       111       217  ...       408       47        559  \\\n",
       "0   -3.642152 -3.045418 -2.082806  ... -5.221357 -4.736862 -7.145763   \n",
       "1    3.864147 -0.848731  0.951730  ... -1.522250 -2.843558 -1.386736   \n",
       "2   -2.228613 -2.627241  2.817279  ... -6.112096 -3.834447 -5.906825   \n",
       "3   -3.546115 -3.819873 -1.148243  ... -5.928733 -4.824050 -8.590173   \n",
       "4   -3.044380 -3.207813 -2.981938  ... -5.774355 -3.830621 -7.278418   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "494  1.056122 -2.675581 -0.692477  ... -3.634108  1.027840 -7.139925   \n",
       "495 -3.080211 -2.189613 -3.882350  ... -6.338565 -4.610166 -9.073524   \n",
       "496 -1.614200 -2.267794 -5.018567  ... -6.109042 -3.481608 -8.051427   \n",
       "497 -2.054919 -1.219164 -3.287626  ... -4.547672 -4.293945 -7.015092   \n",
       "498 -2.773711 -3.739665 -3.838202  ... -4.356044 -4.338513 -7.183603   \n",
       "\n",
       "          10        210       464       424       602       184       268  \n",
       "0   -4.686394 -6.376207 -4.718713 -3.837142 -5.098055 -6.615371 -3.494489  \n",
       "1   -3.607237 -2.620280 -1.531399 -1.628352 -4.333444 -5.644428 -1.784597  \n",
       "2   -4.846343 -4.970954 -4.154849 -3.095449 -5.035297 -7.080035 -2.908712  \n",
       "3   -5.658017 -7.148934 -4.479245 -4.325623 -4.976818 -7.235293 -2.379287  \n",
       "4   -5.184255 -6.954991 -4.763323 -4.439810 -5.881406 -8.004717 -4.863181  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "494 -4.734542 -5.951093 -2.467747 -2.825099 -5.854614 -5.811292 -2.049830  \n",
       "495 -6.186463 -6.666696 -5.512905 -4.706944 -6.450043 -8.598271 -4.921342  \n",
       "496 -5.371017 -6.167434 -4.866140 -5.933562 -5.950708 -5.725215 -4.516814  \n",
       "497 -5.465717 -2.947444 -3.871702 -4.691895 -6.265155 -4.414776 -3.036618  \n",
       "498 -5.877066 -6.523636 -4.800256 -4.452844 -5.873162 -7.251852 -3.685054  \n",
       "\n",
       "[499 rows x 82 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_continuous_df = pd.DataFrame()\n",
    "valid_true_df = pd.DataFrame()\n",
    "for idx in selected_user:\n",
    "    valid_summary = pd.read_csv(\"/home/grigriko/selected_seed3_1e-4/2nd_lr_1e-05/pred/valid_pred_df_output_\" + str(idx) + \".csv\")\n",
    "    valid_continuous_df[idx] = valid_summary['pred_vec']\n",
    "    valid_true_df[idx] = valid_summary['test_vec']\n",
    "valid_continuous_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b8d5122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>474</th>\n",
       "      <th>610</th>\n",
       "      <th>380</th>\n",
       "      <th>249</th>\n",
       "      <th>387</th>\n",
       "      <th>603</th>\n",
       "      <th>232</th>\n",
       "      <th>305</th>\n",
       "      <th>111</th>\n",
       "      <th>217</th>\n",
       "      <th>...</th>\n",
       "      <th>408</th>\n",
       "      <th>47</th>\n",
       "      <th>559</th>\n",
       "      <th>10</th>\n",
       "      <th>210</th>\n",
       "      <th>464</th>\n",
       "      <th>424</th>\n",
       "      <th>602</th>\n",
       "      <th>184</th>\n",
       "      <th>268</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.547049</td>\n",
       "      <td>-1.055014</td>\n",
       "      <td>-0.459644</td>\n",
       "      <td>-0.439059</td>\n",
       "      <td>-0.579634</td>\n",
       "      <td>-0.593624</td>\n",
       "      <td>-1.780321</td>\n",
       "      <td>-1.581784</td>\n",
       "      <td>-0.335448</td>\n",
       "      <td>-0.746359</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.588396</td>\n",
       "      <td>-1.566030</td>\n",
       "      <td>-5.619090</td>\n",
       "      <td>-1.991081</td>\n",
       "      <td>-4.426658</td>\n",
       "      <td>-3.651412</td>\n",
       "      <td>-1.874957</td>\n",
       "      <td>-3.911481</td>\n",
       "      <td>-5.664888</td>\n",
       "      <td>-2.172562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.424052</td>\n",
       "      <td>-1.514613</td>\n",
       "      <td>-0.980284</td>\n",
       "      <td>-0.677451</td>\n",
       "      <td>-1.451296</td>\n",
       "      <td>-1.775315</td>\n",
       "      <td>-1.333548</td>\n",
       "      <td>-2.841205</td>\n",
       "      <td>-0.969537</td>\n",
       "      <td>-3.102422</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.048535</td>\n",
       "      <td>-1.272118</td>\n",
       "      <td>-7.113226</td>\n",
       "      <td>-3.788552</td>\n",
       "      <td>-5.593191</td>\n",
       "      <td>-4.587810</td>\n",
       "      <td>-3.454691</td>\n",
       "      <td>-5.478380</td>\n",
       "      <td>-5.854978</td>\n",
       "      <td>-3.113147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.365125</td>\n",
       "      <td>-1.612946</td>\n",
       "      <td>-1.257959</td>\n",
       "      <td>-1.090382</td>\n",
       "      <td>-1.815320</td>\n",
       "      <td>-1.172521</td>\n",
       "      <td>-1.102018</td>\n",
       "      <td>-2.851369</td>\n",
       "      <td>-3.340336</td>\n",
       "      <td>-3.785435</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.333963</td>\n",
       "      <td>-3.374151</td>\n",
       "      <td>-7.622619</td>\n",
       "      <td>-4.883030</td>\n",
       "      <td>-4.265287</td>\n",
       "      <td>-5.524981</td>\n",
       "      <td>-3.574085</td>\n",
       "      <td>-6.295364</td>\n",
       "      <td>-4.807654</td>\n",
       "      <td>-3.598544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.412127</td>\n",
       "      <td>-1.879194</td>\n",
       "      <td>-1.418643</td>\n",
       "      <td>-0.736964</td>\n",
       "      <td>-1.252934</td>\n",
       "      <td>-1.673491</td>\n",
       "      <td>-1.012760</td>\n",
       "      <td>-3.523673</td>\n",
       "      <td>-1.272917</td>\n",
       "      <td>-2.065845</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.734542</td>\n",
       "      <td>-4.464528</td>\n",
       "      <td>-7.873002</td>\n",
       "      <td>-4.219541</td>\n",
       "      <td>-6.181481</td>\n",
       "      <td>-5.472957</td>\n",
       "      <td>-3.601971</td>\n",
       "      <td>-5.363523</td>\n",
       "      <td>-6.744331</td>\n",
       "      <td>-3.371820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.450590</td>\n",
       "      <td>-1.291778</td>\n",
       "      <td>-1.135946</td>\n",
       "      <td>-1.262173</td>\n",
       "      <td>-1.053673</td>\n",
       "      <td>-0.757487</td>\n",
       "      <td>-2.088439</td>\n",
       "      <td>-3.129662</td>\n",
       "      <td>-2.066783</td>\n",
       "      <td>-1.621758</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.457639</td>\n",
       "      <td>-3.576903</td>\n",
       "      <td>-5.891741</td>\n",
       "      <td>-4.249879</td>\n",
       "      <td>-6.473554</td>\n",
       "      <td>-4.366154</td>\n",
       "      <td>-3.934770</td>\n",
       "      <td>-5.280930</td>\n",
       "      <td>-4.730837</td>\n",
       "      <td>-2.738204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>-0.525665</td>\n",
       "      <td>-1.312869</td>\n",
       "      <td>-1.370655</td>\n",
       "      <td>-1.217013</td>\n",
       "      <td>-1.817365</td>\n",
       "      <td>-1.452704</td>\n",
       "      <td>-0.828315</td>\n",
       "      <td>-3.649686</td>\n",
       "      <td>-2.730826</td>\n",
       "      <td>-4.823743</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.116138</td>\n",
       "      <td>-3.688073</td>\n",
       "      <td>-9.199656</td>\n",
       "      <td>-4.065544</td>\n",
       "      <td>-6.381269</td>\n",
       "      <td>-5.028703</td>\n",
       "      <td>-5.477179</td>\n",
       "      <td>-6.447706</td>\n",
       "      <td>-7.526871</td>\n",
       "      <td>-4.180612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>-0.683728</td>\n",
       "      <td>-2.003858</td>\n",
       "      <td>-1.395178</td>\n",
       "      <td>-0.478394</td>\n",
       "      <td>-2.091506</td>\n",
       "      <td>-1.559177</td>\n",
       "      <td>-2.506045</td>\n",
       "      <td>-4.325069</td>\n",
       "      <td>-3.180517</td>\n",
       "      <td>-3.214834</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.653145</td>\n",
       "      <td>-4.083614</td>\n",
       "      <td>-8.898437</td>\n",
       "      <td>-5.055035</td>\n",
       "      <td>-6.489996</td>\n",
       "      <td>-4.193641</td>\n",
       "      <td>-5.388522</td>\n",
       "      <td>-6.206732</td>\n",
       "      <td>-7.398435</td>\n",
       "      <td>-4.328698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>-0.675474</td>\n",
       "      <td>-1.397658</td>\n",
       "      <td>-1.201629</td>\n",
       "      <td>-1.444677</td>\n",
       "      <td>-1.450410</td>\n",
       "      <td>-1.418273</td>\n",
       "      <td>-2.614353</td>\n",
       "      <td>-3.942857</td>\n",
       "      <td>-2.105082</td>\n",
       "      <td>-1.007398</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.364093</td>\n",
       "      <td>-4.892274</td>\n",
       "      <td>-7.888306</td>\n",
       "      <td>-5.286541</td>\n",
       "      <td>-5.547813</td>\n",
       "      <td>-4.129516</td>\n",
       "      <td>-4.028743</td>\n",
       "      <td>-5.294003</td>\n",
       "      <td>-6.529675</td>\n",
       "      <td>-3.266044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6998</th>\n",
       "      <td>-0.587225</td>\n",
       "      <td>-0.591720</td>\n",
       "      <td>-0.660866</td>\n",
       "      <td>-1.304135</td>\n",
       "      <td>-1.662852</td>\n",
       "      <td>-1.727885</td>\n",
       "      <td>-2.029429</td>\n",
       "      <td>-3.535971</td>\n",
       "      <td>-2.938642</td>\n",
       "      <td>-3.964688</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.922319</td>\n",
       "      <td>-4.134452</td>\n",
       "      <td>-6.736932</td>\n",
       "      <td>-3.698004</td>\n",
       "      <td>-4.184235</td>\n",
       "      <td>-4.660151</td>\n",
       "      <td>-5.354767</td>\n",
       "      <td>-5.885217</td>\n",
       "      <td>-5.594655</td>\n",
       "      <td>-3.621347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>-0.362923</td>\n",
       "      <td>-0.378523</td>\n",
       "      <td>-0.498914</td>\n",
       "      <td>-0.448706</td>\n",
       "      <td>-1.480846</td>\n",
       "      <td>-1.074019</td>\n",
       "      <td>-2.055239</td>\n",
       "      <td>-2.735088</td>\n",
       "      <td>-1.670303</td>\n",
       "      <td>-3.267927</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.268126</td>\n",
       "      <td>-4.094919</td>\n",
       "      <td>-7.205475</td>\n",
       "      <td>-2.472006</td>\n",
       "      <td>-4.875783</td>\n",
       "      <td>-5.477198</td>\n",
       "      <td>-5.424128</td>\n",
       "      <td>-6.642587</td>\n",
       "      <td>-4.370299</td>\n",
       "      <td>-3.054960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           474       610       380       249       387       603       232  \\\n",
       "0    -0.547049 -1.055014 -0.459644 -0.439059 -0.579634 -0.593624 -1.780321   \n",
       "1    -0.424052 -1.514613 -0.980284 -0.677451 -1.451296 -1.775315 -1.333548   \n",
       "2    -0.365125 -1.612946 -1.257959 -1.090382 -1.815320 -1.172521 -1.102018   \n",
       "3    -0.412127 -1.879194 -1.418643 -0.736964 -1.252934 -1.673491 -1.012760   \n",
       "4    -0.450590 -1.291778 -1.135946 -1.262173 -1.053673 -0.757487 -2.088439   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6995 -0.525665 -1.312869 -1.370655 -1.217013 -1.817365 -1.452704 -0.828315   \n",
       "6996 -0.683728 -2.003858 -1.395178 -0.478394 -2.091506 -1.559177 -2.506045   \n",
       "6997 -0.675474 -1.397658 -1.201629 -1.444677 -1.450410 -1.418273 -2.614353   \n",
       "6998 -0.587225 -0.591720 -0.660866 -1.304135 -1.662852 -1.727885 -2.029429   \n",
       "6999 -0.362923 -0.378523 -0.498914 -0.448706 -1.480846 -1.074019 -2.055239   \n",
       "\n",
       "           305       111       217  ...       408       47        559  \\\n",
       "0    -1.581784 -0.335448 -0.746359  ... -3.588396 -1.566030 -5.619090   \n",
       "1    -2.841205 -0.969537 -3.102422  ... -5.048535 -1.272118 -7.113226   \n",
       "2    -2.851369 -3.340336 -3.785435  ... -6.333963 -3.374151 -7.622619   \n",
       "3    -3.523673 -1.272917 -2.065845  ... -5.734542 -4.464528 -7.873002   \n",
       "4    -3.129662 -2.066783 -1.621758  ... -5.457639 -3.576903 -5.891741   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "6995 -3.649686 -2.730826 -4.823743  ... -5.116138 -3.688073 -9.199656   \n",
       "6996 -4.325069 -3.180517 -3.214834  ... -3.653145 -4.083614 -8.898437   \n",
       "6997 -3.942857 -2.105082 -1.007398  ... -4.364093 -4.892274 -7.888306   \n",
       "6998 -3.535971 -2.938642 -3.964688  ... -4.922319 -4.134452 -6.736932   \n",
       "6999 -2.735088 -1.670303 -3.267927  ... -4.268126 -4.094919 -7.205475   \n",
       "\n",
       "           10        210       464       424       602       184       268  \n",
       "0    -1.991081 -4.426658 -3.651412 -1.874957 -3.911481 -5.664888 -2.172562  \n",
       "1    -3.788552 -5.593191 -4.587810 -3.454691 -5.478380 -5.854978 -3.113147  \n",
       "2    -4.883030 -4.265287 -5.524981 -3.574085 -6.295364 -4.807654 -3.598544  \n",
       "3    -4.219541 -6.181481 -5.472957 -3.601971 -5.363523 -6.744331 -3.371820  \n",
       "4    -4.249879 -6.473554 -4.366154 -3.934770 -5.280930 -4.730837 -2.738204  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "6995 -4.065544 -6.381269 -5.028703 -5.477179 -6.447706 -7.526871 -4.180612  \n",
       "6996 -5.055035 -6.489996 -4.193641 -5.388522 -6.206732 -7.398435 -4.328698  \n",
       "6997 -5.286541 -5.547813 -4.129516 -4.028743 -5.294003 -6.529675 -3.266044  \n",
       "6998 -3.698004 -4.184235 -4.660151 -5.354767 -5.885217 -5.594655 -3.621347  \n",
       "6999 -2.472006 -4.875783 -5.477198 -5.424128 -6.642587 -4.370299 -3.054960  \n",
       "\n",
       "[7000 rows x 82 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_continuous_df = pd.DataFrame()\n",
    "test_true_df = pd.DataFrame()\n",
    "for idx in selected_user:\n",
    "    test_summary = pd.read_csv(\"/home/grigriko/selected_seed3_1e-4/2nd_lr_1e-05/test/pred_df_output\" + str(idx) + \".csv\")\n",
    "    test_continuous_df[idx] = test_summary['pred_vec']\n",
    "    test_true_df[idx] = test_summary['test_vec']\n",
    "\n",
    "test_continuous_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23dd8169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>474</th>\n",
       "      <th>610</th>\n",
       "      <th>380</th>\n",
       "      <th>249</th>\n",
       "      <th>387</th>\n",
       "      <th>182</th>\n",
       "      <th>603</th>\n",
       "      <th>232</th>\n",
       "      <th>608</th>\n",
       "      <th>19</th>\n",
       "      <th>...</th>\n",
       "      <th>7</th>\n",
       "      <th>326</th>\n",
       "      <th>113</th>\n",
       "      <th>100</th>\n",
       "      <th>137</th>\n",
       "      <th>129</th>\n",
       "      <th>10</th>\n",
       "      <th>210</th>\n",
       "      <th>376</th>\n",
       "      <th>369</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.079527</td>\n",
       "      <td>0.288472</td>\n",
       "      <td>0.404921</td>\n",
       "      <td>0.430871</td>\n",
       "      <td>0.169701</td>\n",
       "      <td>0.147374</td>\n",
       "      <td>0.186351</td>\n",
       "      <td>0.714438</td>\n",
       "      <td>0.271479</td>\n",
       "      <td>0.701893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279277</td>\n",
       "      <td>0.280683</td>\n",
       "      <td>0.431000</td>\n",
       "      <td>0.598776</td>\n",
       "      <td>0.272133</td>\n",
       "      <td>0.316478</td>\n",
       "      <td>0.611443</td>\n",
       "      <td>0.453972</td>\n",
       "      <td>0.218624</td>\n",
       "      <td>0.318533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.049396</td>\n",
       "      <td>0.263223</td>\n",
       "      <td>0.388354</td>\n",
       "      <td>0.332695</td>\n",
       "      <td>0.101232</td>\n",
       "      <td>0.068080</td>\n",
       "      <td>0.055588</td>\n",
       "      <td>0.702580</td>\n",
       "      <td>0.267015</td>\n",
       "      <td>0.410564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247596</td>\n",
       "      <td>0.251555</td>\n",
       "      <td>0.268026</td>\n",
       "      <td>0.393683</td>\n",
       "      <td>0.245419</td>\n",
       "      <td>0.291713</td>\n",
       "      <td>0.295348</td>\n",
       "      <td>0.315569</td>\n",
       "      <td>0.198028</td>\n",
       "      <td>0.297012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.092849</td>\n",
       "      <td>0.238809</td>\n",
       "      <td>0.376009</td>\n",
       "      <td>0.236493</td>\n",
       "      <td>0.083251</td>\n",
       "      <td>0.223896</td>\n",
       "      <td>0.150509</td>\n",
       "      <td>0.713396</td>\n",
       "      <td>0.197638</td>\n",
       "      <td>0.460750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201060</td>\n",
       "      <td>0.516403</td>\n",
       "      <td>0.273833</td>\n",
       "      <td>0.252681</td>\n",
       "      <td>0.183966</td>\n",
       "      <td>0.180769</td>\n",
       "      <td>0.243890</td>\n",
       "      <td>0.394428</td>\n",
       "      <td>0.178918</td>\n",
       "      <td>0.192993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.079268</td>\n",
       "      <td>0.238536</td>\n",
       "      <td>0.339495</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.124085</td>\n",
       "      <td>0.182486</td>\n",
       "      <td>0.150350</td>\n",
       "      <td>0.709868</td>\n",
       "      <td>0.222883</td>\n",
       "      <td>0.516913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193604</td>\n",
       "      <td>0.289359</td>\n",
       "      <td>0.284711</td>\n",
       "      <td>0.314157</td>\n",
       "      <td>0.117581</td>\n",
       "      <td>0.137404</td>\n",
       "      <td>0.305625</td>\n",
       "      <td>0.252180</td>\n",
       "      <td>0.185244</td>\n",
       "      <td>0.156988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.069964</td>\n",
       "      <td>0.271008</td>\n",
       "      <td>0.356254</td>\n",
       "      <td>0.232271</td>\n",
       "      <td>0.298970</td>\n",
       "      <td>0.238715</td>\n",
       "      <td>0.153305</td>\n",
       "      <td>0.674385</td>\n",
       "      <td>0.151070</td>\n",
       "      <td>0.589166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202952</td>\n",
       "      <td>0.428776</td>\n",
       "      <td>0.275748</td>\n",
       "      <td>0.265646</td>\n",
       "      <td>0.228404</td>\n",
       "      <td>0.194056</td>\n",
       "      <td>0.312247</td>\n",
       "      <td>0.286325</td>\n",
       "      <td>0.172822</td>\n",
       "      <td>0.264854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>0.041755</td>\n",
       "      <td>0.269365</td>\n",
       "      <td>0.334971</td>\n",
       "      <td>0.254991</td>\n",
       "      <td>0.081832</td>\n",
       "      <td>0.099599</td>\n",
       "      <td>0.042621</td>\n",
       "      <td>0.680971</td>\n",
       "      <td>0.104392</td>\n",
       "      <td>0.403495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178657</td>\n",
       "      <td>0.281895</td>\n",
       "      <td>0.196525</td>\n",
       "      <td>0.351243</td>\n",
       "      <td>0.243684</td>\n",
       "      <td>0.168350</td>\n",
       "      <td>0.372869</td>\n",
       "      <td>0.317390</td>\n",
       "      <td>0.148905</td>\n",
       "      <td>0.178263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>0.023271</td>\n",
       "      <td>0.242207</td>\n",
       "      <td>0.320172</td>\n",
       "      <td>0.223592</td>\n",
       "      <td>0.054778</td>\n",
       "      <td>0.300147</td>\n",
       "      <td>0.027104</td>\n",
       "      <td>0.670064</td>\n",
       "      <td>0.117137</td>\n",
       "      <td>0.418465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242663</td>\n",
       "      <td>0.188242</td>\n",
       "      <td>0.273231</td>\n",
       "      <td>0.226820</td>\n",
       "      <td>0.104618</td>\n",
       "      <td>0.267617</td>\n",
       "      <td>0.189527</td>\n",
       "      <td>0.271526</td>\n",
       "      <td>0.103676</td>\n",
       "      <td>0.178083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.252650</td>\n",
       "      <td>0.339635</td>\n",
       "      <td>0.225708</td>\n",
       "      <td>0.190581</td>\n",
       "      <td>0.100677</td>\n",
       "      <td>0.053783</td>\n",
       "      <td>0.657770</td>\n",
       "      <td>0.156407</td>\n",
       "      <td>0.619528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195854</td>\n",
       "      <td>0.216586</td>\n",
       "      <td>0.260526</td>\n",
       "      <td>0.241195</td>\n",
       "      <td>0.146241</td>\n",
       "      <td>0.233219</td>\n",
       "      <td>0.254967</td>\n",
       "      <td>0.283381</td>\n",
       "      <td>0.180020</td>\n",
       "      <td>0.225642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6998</th>\n",
       "      <td>0.036466</td>\n",
       "      <td>0.274897</td>\n",
       "      <td>0.441871</td>\n",
       "      <td>0.283486</td>\n",
       "      <td>0.107300</td>\n",
       "      <td>0.162375</td>\n",
       "      <td>0.073937</td>\n",
       "      <td>0.714250</td>\n",
       "      <td>0.152627</td>\n",
       "      <td>0.445843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.276805</td>\n",
       "      <td>0.387915</td>\n",
       "      <td>0.247352</td>\n",
       "      <td>0.181026</td>\n",
       "      <td>0.251784</td>\n",
       "      <td>0.267179</td>\n",
       "      <td>0.384728</td>\n",
       "      <td>0.408503</td>\n",
       "      <td>0.210827</td>\n",
       "      <td>0.223798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>0.117314</td>\n",
       "      <td>0.306541</td>\n",
       "      <td>0.437080</td>\n",
       "      <td>0.320470</td>\n",
       "      <td>0.084847</td>\n",
       "      <td>0.226212</td>\n",
       "      <td>0.151114</td>\n",
       "      <td>0.723548</td>\n",
       "      <td>0.211323</td>\n",
       "      <td>0.454193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179968</td>\n",
       "      <td>0.308632</td>\n",
       "      <td>0.252885</td>\n",
       "      <td>0.285986</td>\n",
       "      <td>0.165071</td>\n",
       "      <td>0.222703</td>\n",
       "      <td>0.400747</td>\n",
       "      <td>0.370289</td>\n",
       "      <td>0.198812</td>\n",
       "      <td>0.197929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           474       610       380       249       387       182       603  \\\n",
       "0     0.079527  0.288472  0.404921  0.430871  0.169701  0.147374  0.186351   \n",
       "1     0.049396  0.263223  0.388354  0.332695  0.101232  0.068080  0.055588   \n",
       "2     0.092849  0.238809  0.376009  0.236493  0.083251  0.223896  0.150509   \n",
       "3     0.079268  0.238536  0.339495  0.246536  0.124085  0.182486  0.150350   \n",
       "4     0.069964  0.271008  0.356254  0.232271  0.298970  0.238715  0.153305   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6995  0.041755  0.269365  0.334971  0.254991  0.081832  0.099599  0.042621   \n",
       "6996  0.023271  0.242207  0.320172  0.223592  0.054778  0.300147  0.027104   \n",
       "6997  0.014064  0.252650  0.339635  0.225708  0.190581  0.100677  0.053783   \n",
       "6998  0.036466  0.274897  0.441871  0.283486  0.107300  0.162375  0.073937   \n",
       "6999  0.117314  0.306541  0.437080  0.320470  0.084847  0.226212  0.151114   \n",
       "\n",
       "           232       608       19   ...       7         326       113  \\\n",
       "0     0.714438  0.271479  0.701893  ...  0.279277  0.280683  0.431000   \n",
       "1     0.702580  0.267015  0.410564  ...  0.247596  0.251555  0.268026   \n",
       "2     0.713396  0.197638  0.460750  ...  0.201060  0.516403  0.273833   \n",
       "3     0.709868  0.222883  0.516913  ...  0.193604  0.289359  0.284711   \n",
       "4     0.674385  0.151070  0.589166  ...  0.202952  0.428776  0.275748   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "6995  0.680971  0.104392  0.403495  ...  0.178657  0.281895  0.196525   \n",
       "6996  0.670064  0.117137  0.418465  ...  0.242663  0.188242  0.273231   \n",
       "6997  0.657770  0.156407  0.619528  ...  0.195854  0.216586  0.260526   \n",
       "6998  0.714250  0.152627  0.445843  ...  0.276805  0.387915  0.247352   \n",
       "6999  0.723548  0.211323  0.454193  ...  0.179968  0.308632  0.252885   \n",
       "\n",
       "           100       137       129       10        210       376       369  \n",
       "0     0.598776  0.272133  0.316478  0.611443  0.453972  0.218624  0.318533  \n",
       "1     0.393683  0.245419  0.291713  0.295348  0.315569  0.198028  0.297012  \n",
       "2     0.252681  0.183966  0.180769  0.243890  0.394428  0.178918  0.192993  \n",
       "3     0.314157  0.117581  0.137404  0.305625  0.252180  0.185244  0.156988  \n",
       "4     0.265646  0.228404  0.194056  0.312247  0.286325  0.172822  0.264854  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "6995  0.351243  0.243684  0.168350  0.372869  0.317390  0.148905  0.178263  \n",
       "6996  0.226820  0.104618  0.267617  0.189527  0.271526  0.103676  0.178083  \n",
       "6997  0.241195  0.146241  0.233219  0.254967  0.283381  0.180020  0.225642  \n",
       "6998  0.181026  0.251784  0.267179  0.384728  0.408503  0.210827  0.223798  \n",
       "6999  0.285986  0.165071  0.222703  0.400747  0.370289  0.198812  0.197929  \n",
       "\n",
       "[7000 rows x 82 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_continuous_normed = pd.DataFrame()\n",
    "# for col in test_continuous_df.columns:\n",
    "#     min = test_continuous_df[col].min()\n",
    "#     max = test_continuous_df[col].max()\n",
    "#     test_continuous_normed[col] = test_continuous_df[col].apply(lambda x: (x-min) / (max - min))\n",
    "# test_continuous_normed     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19cdd63e",
   "metadata": {
    "scrolled": true
   },
   {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_169/1092732248.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sim[str(column)] = weight_list\n",
      "/tmp/ipykernel_169/1092732248.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sim[str(column)] = weight_list\n",
      "/tmp/ipykernel_169/1092732248.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sim[str(column)] = weight_list\n",
      "/tmp/ipykernel_169/1092732248.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sim[str(column)] = weight_list\n",
      "/tmp/ipykernel_169/1092732248.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sim[str(column)] = weight_list\n",
      "/tmp/ipykernel_169/1092732248.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sim[str(column)] = weight_list\n",
      "/tmp/ipykernel_169/1092732248.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sim[str(column)] = weight_list\n",
      "/tmp/ipykernel_169/1092732248.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sim[str(column)] = weight_list\n",
      "/tmp/ipykernel_169/1092732248.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sim[str(column)] = weight_list\n",
      "/tmp/ipykernel_169/1092732248.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sim[str(column)] = weight_list\n",
      "/tmp/ipykernel_169/1092732248.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sim[str(column)] = weight_list\n",
      "/tmp/ipykernel_169/1092732248.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sim[str(column)] = weight_list\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>414</th>\n",
       "      <th>599</th>\n",
       "      <th>448</th>\n",
       "      <th>274</th>\n",
       "      <th>68</th>\n",
       "      <th>606</th>\n",
       "      <th>288</th>\n",
       "      <th>182</th>\n",
       "      <th>307</th>\n",
       "      <th>298</th>\n",
       "      <th>...</th>\n",
       "      <th>408</th>\n",
       "      <th>47</th>\n",
       "      <th>559</th>\n",
       "      <th>10</th>\n",
       "      <th>210</th>\n",
       "      <th>464</th>\n",
       "      <th>424</th>\n",
       "      <th>602</th>\n",
       "      <th>184</th>\n",
       "      <th>268</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.012020</td>\n",
       "      <td>0.006756</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>-0.026801</td>\n",
       "      <td>-0.022413</td>\n",
       "      <td>0.008459</td>\n",
       "      <td>0.021169</td>\n",
       "      <td>-0.031284</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>-0.013855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.015978</td>\n",
       "      <td>-0.003739</td>\n",
       "      <td>0.004335</td>\n",
       "      <td>-0.004486</td>\n",
       "      <td>-0.005411</td>\n",
       "      <td>-0.005415</td>\n",
       "      <td>-0.010466</td>\n",
       "      <td>0.005877</td>\n",
       "      <td>0.006503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.011354</td>\n",
       "      <td>0.019595</td>\n",
       "      <td>0.023533</td>\n",
       "      <td>0.037106</td>\n",
       "      <td>-0.006909</td>\n",
       "      <td>-0.003912</td>\n",
       "      <td>0.001727</td>\n",
       "      <td>0.009455</td>\n",
       "      <td>0.016246</td>\n",
       "      <td>0.032465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002077</td>\n",
       "      <td>-0.011704</td>\n",
       "      <td>-0.001215</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>-0.001740</td>\n",
       "      <td>0.001428</td>\n",
       "      <td>-0.000603</td>\n",
       "      <td>-0.001538</td>\n",
       "      <td>-0.002101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.006915</td>\n",
       "      <td>-0.003060</td>\n",
       "      <td>0.014282</td>\n",
       "      <td>-0.010981</td>\n",
       "      <td>-0.020499</td>\n",
       "      <td>-0.015308</td>\n",
       "      <td>-0.008728</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017382</td>\n",
       "      <td>-0.007890</td>\n",
       "      <td>0.008224</td>\n",
       "      <td>-0.009492</td>\n",
       "      <td>-0.012683</td>\n",
       "      <td>-0.010093</td>\n",
       "      <td>-0.004650</td>\n",
       "      <td>-0.002075</td>\n",
       "      <td>0.009073</td>\n",
       "      <td>-0.004931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.003393</td>\n",
       "      <td>-0.002796</td>\n",
       "      <td>0.011151</td>\n",
       "      <td>0.020055</td>\n",
       "      <td>0.014898</td>\n",
       "      <td>-0.005966</td>\n",
       "      <td>-0.016170</td>\n",
       "      <td>-0.010469</td>\n",
       "      <td>-0.006073</td>\n",
       "      <td>0.015317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>-0.006131</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>-0.007740</td>\n",
       "      <td>0.003317</td>\n",
       "      <td>-0.004895</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>-0.000356</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>-0.010351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.008265</td>\n",
       "      <td>0.019198</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>0.004321</td>\n",
       "      <td>0.003293</td>\n",
       "      <td>0.002270</td>\n",
       "      <td>0.009886</td>\n",
       "      <td>0.000980</td>\n",
       "      <td>0.004872</td>\n",
       "      <td>0.008234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002393</td>\n",
       "      <td>-0.009260</td>\n",
       "      <td>-0.005167</td>\n",
       "      <td>0.003181</td>\n",
       "      <td>-0.002036</td>\n",
       "      <td>0.004731</td>\n",
       "      <td>0.019875</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.001618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>-0.005853</td>\n",
       "      <td>-0.002006</td>\n",
       "      <td>-0.011408</td>\n",
       "      <td>0.002243</td>\n",
       "      <td>-0.001191</td>\n",
       "      <td>0.006012</td>\n",
       "      <td>-0.002990</td>\n",
       "      <td>0.004105</td>\n",
       "      <td>-0.009231</td>\n",
       "      <td>-0.006650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>-0.001446</td>\n",
       "      <td>-0.000652</td>\n",
       "      <td>0.001960</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002042</td>\n",
       "      <td>0.004862</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.002600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>-0.005823</td>\n",
       "      <td>-0.003507</td>\n",
       "      <td>0.004552</td>\n",
       "      <td>0.006231</td>\n",
       "      <td>-0.009451</td>\n",
       "      <td>0.002968</td>\n",
       "      <td>-0.002411</td>\n",
       "      <td>0.003187</td>\n",
       "      <td>0.014841</td>\n",
       "      <td>0.000965</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004224</td>\n",
       "      <td>0.002566</td>\n",
       "      <td>-0.001634</td>\n",
       "      <td>-0.005429</td>\n",
       "      <td>-0.002757</td>\n",
       "      <td>-0.000351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001829</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.003319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.006690</td>\n",
       "      <td>-0.005948</td>\n",
       "      <td>0.003526</td>\n",
       "      <td>-0.002482</td>\n",
       "      <td>-0.002262</td>\n",
       "      <td>-0.001522</td>\n",
       "      <td>-0.002522</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>-0.001943</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000976</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.016391</td>\n",
       "      <td>-0.002050</td>\n",
       "      <td>-0.002567</td>\n",
       "      <td>0.002980</td>\n",
       "      <td>-0.000215</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000064</td>\n",
       "      <td>-0.005052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.005736</td>\n",
       "      <td>0.014110</td>\n",
       "      <td>0.006622</td>\n",
       "      <td>-0.010725</td>\n",
       "      <td>-0.004563</td>\n",
       "      <td>-0.006155</td>\n",
       "      <td>0.003410</td>\n",
       "      <td>-0.001484</td>\n",
       "      <td>-0.001524</td>\n",
       "      <td>0.004707</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001175</td>\n",
       "      <td>-0.000933</td>\n",
       "      <td>-0.003908</td>\n",
       "      <td>-0.000430</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>0.002664</td>\n",
       "      <td>-0.004765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>-0.001895</td>\n",
       "      <td>0.003373</td>\n",
       "      <td>-0.003783</td>\n",
       "      <td>0.012037</td>\n",
       "      <td>0.004190</td>\n",
       "      <td>0.005273</td>\n",
       "      <td>-0.008540</td>\n",
       "      <td>-0.017565</td>\n",
       "      <td>-0.001761</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004300</td>\n",
       "      <td>-0.002786</td>\n",
       "      <td>-0.011963</td>\n",
       "      <td>-0.002059</td>\n",
       "      <td>-0.001473</td>\n",
       "      <td>0.011951</td>\n",
       "      <td>0.009412</td>\n",
       "      <td>-0.016442</td>\n",
       "      <td>-0.008364</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows × 194 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         414       599       448       274        68       606       288  \\\n",
       "0   0.012020  0.006756  0.000838 -0.026801 -0.022413  0.008459  0.021169   \n",
       "1   0.011354  0.019595  0.023533  0.037106 -0.006909 -0.003912  0.001727   \n",
       "2   0.000253  0.000438  0.006915 -0.003060  0.014282 -0.010981 -0.020499   \n",
       "3  -0.003393 -0.002796  0.011151  0.020055  0.014898 -0.005966 -0.016170   \n",
       "4  -0.008265  0.019198  0.005261  0.004321  0.003293  0.002270  0.009886   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "77 -0.005853 -0.002006 -0.011408  0.002243 -0.001191  0.006012 -0.002990   \n",
       "78 -0.005823 -0.003507  0.004552  0.006231 -0.009451  0.002968 -0.002411   \n",
       "79  0.006690 -0.005948  0.003526 -0.002482 -0.002262 -0.001522 -0.002522   \n",
       "80  0.005736  0.014110  0.006622 -0.010725 -0.004563 -0.006155  0.003410   \n",
       "81 -0.001895  0.003373 -0.003783  0.012037  0.004190  0.005273 -0.008540   \n",
       "\n",
       "         182       307       298  ...       408        47       559        10  \\\n",
       "0  -0.031284  0.006251 -0.013855  ...  0.000558  0.015978 -0.003739  0.004335   \n",
       "1   0.009455  0.016246  0.032465  ...  0.002077 -0.011704 -0.001215 -0.000106   \n",
       "2  -0.015308 -0.008728  0.000591  ...  0.017382 -0.007890  0.008224 -0.009492   \n",
       "3  -0.010469 -0.006073  0.015317  ...  0.000654 -0.006131  0.000884 -0.007740   \n",
       "4   0.000980  0.004872  0.008234  ...  0.002393 -0.009260 -0.005167  0.003181   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "77  0.004105 -0.009231 -0.006650  ...  0.001709 -0.001446 -0.000652  0.001960   \n",
       "78  0.003187  0.014841  0.000965  ... -0.004224  0.002566 -0.001634 -0.005429   \n",
       "79  0.004902 -0.001943  0.000633  ... -0.000976  0.002574  0.016391 -0.002050   \n",
       "80 -0.001484 -0.001524  0.004707  ... -0.001175 -0.000933 -0.003908 -0.000430   \n",
       "81 -0.017565 -0.001761  0.001876  ... -0.004300 -0.002786 -0.011963 -0.002059   \n",
       "\n",
       "         210       464       424       602       184       268  \n",
       "0  -0.004486 -0.005411 -0.005415 -0.010466  0.005877  0.006503  \n",
       "1   0.000768 -0.001740  0.001428 -0.000603 -0.001538 -0.002101  \n",
       "2  -0.012683 -0.010093 -0.004650 -0.002075  0.009073 -0.004931  \n",
       "3   0.003317 -0.004895  0.001997 -0.000356  0.000298 -0.010351  \n",
       "4  -0.002036  0.004731  0.019875  0.001297  0.000017 -0.001618  \n",
       "..       ...       ...       ...       ...       ...       ...  \n",
       "77  0.001307  0.000000 -0.002042  0.004862  0.000499  0.002600  \n",
       "78 -0.002757 -0.000351  0.000000 -0.001829 -0.000002  0.003319  \n",
       "79 -0.002567  0.002980 -0.000215  0.000000 -0.000064 -0.005052  \n",
       "80  0.001327  0.000988  0.002664 -0.004765  0.000000 -0.002779  \n",
       "81 -0.001473  0.011951  0.009412 -0.016442 -0.008364  0.000000  \n",
       "\n",
       "[82 rows x 194 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CF-Continuous\n",
    "model_lr = LinearRegression()\n",
    "option = \"continuous_\" # distinguish continous/binary\n",
    "\n",
    "selected = train_continuous_df#行がmovieid, 列がuseridの評価値dataframe\n",
    "rest = rest_true_train\n",
    "mean = 0#all_true_train.mean()#各ユーザーの評価値の平均(列ごとに計算してdataframeを返す)\n",
    "\n",
    "sim = pd.DataFrame() # initialize sim\n",
    "\n",
    "for column in rest:\n",
    "    model_lr.fit(selected, rest[column])\n",
    "    coef = pd.Series(model_lr.coef_)\n",
    "    sim = pd.concat([sim, coef], axis=1)# = model_lr.coef_\n",
    "sim.columns = rest.columns.astype(str)\n",
    "sim\n",
    "idx = 0\n",
    "for column in selected:\n",
    "    except_selected = selected.drop(column, axis=1)\n",
    "    model_lr.fit(except_selected, train_true_df[column])\n",
    "    weight_list = model_lr.coef_.tolist()\n",
    "    weight_list.insert(idx, 0)\n",
    "    sim[str(column)] = weight_list\n",
    "    idx += 1\n",
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74aa924d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.index = selected_user\n",
    "# sim.columns = subj_idx#一時バグの原因になっていた\n",
    "sim.to_csv(\"/home/grigriko/collaborative_filtering/regression_continuous/regression_sim_0511.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27548692",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "474    0.000000\n",
       "610   -0.014677\n",
       "380   -0.007124\n",
       "249   -0.031167\n",
       "387    0.017781\n",
       "         ...   \n",
       "464   -0.000121\n",
       "424   -0.000472\n",
       "602    0.001248\n",
       "184   -0.003286\n",
       "268    0.008534\n",
       "Name: 474, Length: 82, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim['474']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce211139",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = pd.DataFrame()\n",
    "for uid in subj_idx:\n",
    "    \n",
    "    pred_vals = []\n",
    "\n",
    "    dim = len(selected.columns)\n",
    "    sim_vec = sim.loc[:,uid].to_numpy().reshape((dim, 1)) # shape (40,1), dot積を計算できるようにする\n",
    "\n",
    "    for iid in range(len(valid_continuous_df)):\n",
    "        rate_vec = valid_continuous_df\n",
    "        rate_vec = rate_vec.loc[iid,:].to_numpy().reshape((1, dim))#movieidごとの各userの予測値, shape (1, 40)\n",
    "        if sim_vec.sum() == 0:\n",
    "            score = np.array([0])\n",
    "            print(f'sim_vec.sum() = 0!!!')\n",
    "        else: \n",
    "#             print(f'np.dot(rate_vec, sim_vec): {np.dot(rate_vec, sim_vec)[0][0]}')#1行40列と40行1列の積→1行1列の行列ができる\n",
    "            if np.dot(rate_vec, sim_vec)[0][0]==0:\n",
    "                print(f'sim_vec: {sim_vec}')\n",
    "              # print(f'rate_vec: {rate_vec}')\n",
    "#             print(f'mean[{uid}]: {mean[uid]}')\n",
    "#             print(f'sim_vec.sum(): {sim_vec.sum()}')\n",
    "            score = (np.dot(rate_vec, sim_vec)/(sim_vec.sum()))[0][0]#main # score = self.mean[uid] + np.dot(rate_vec, sim_vec)/(sim_vec.sum())\n",
    "#             print(f'score:{score}')\n",
    "        pred_vals.append(score)\n",
    "    df_valid[uid] = pred_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b9b8e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>414</th>\n",
       "      <th>599</th>\n",
       "      <th>474</th>\n",
       "      <th>448</th>\n",
       "      <th>274</th>\n",
       "      <th>610</th>\n",
       "      <th>68</th>\n",
       "      <th>380</th>\n",
       "      <th>606</th>\n",
       "      <th>288</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>27</th>\n",
       "      <th>184</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>524</th>\n",
       "      <th>52</th>\n",
       "      <th>268</th>\n",
       "      <th>369</th>\n",
       "      <th>314</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.115953</td>\n",
       "      <td>-2.882551</td>\n",
       "      <td>-4.728258</td>\n",
       "      <td>-2.525126</td>\n",
       "      <td>-2.760124</td>\n",
       "      <td>-9.337418</td>\n",
       "      <td>-4.686259</td>\n",
       "      <td>-2.190597</td>\n",
       "      <td>-4.136896</td>\n",
       "      <td>-2.567320</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.885970</td>\n",
       "      <td>-1.085753</td>\n",
       "      <td>-2.794318</td>\n",
       "      <td>-3.953106</td>\n",
       "      <td>-3.176873</td>\n",
       "      <td>-3.743190</td>\n",
       "      <td>-5.550285</td>\n",
       "      <td>-2.723604</td>\n",
       "      <td>-6.304630</td>\n",
       "      <td>-3.653785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.177609</td>\n",
       "      <td>-1.555334</td>\n",
       "      <td>-0.151824</td>\n",
       "      <td>2.140778</td>\n",
       "      <td>6.779421</td>\n",
       "      <td>4.791630</td>\n",
       "      <td>-0.184555</td>\n",
       "      <td>6.122128</td>\n",
       "      <td>-2.806886</td>\n",
       "      <td>1.566354</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.710675</td>\n",
       "      <td>2.648918</td>\n",
       "      <td>1.545335</td>\n",
       "      <td>-0.728034</td>\n",
       "      <td>-2.532983</td>\n",
       "      <td>-1.035239</td>\n",
       "      <td>-0.075564</td>\n",
       "      <td>-0.515175</td>\n",
       "      <td>-2.241114</td>\n",
       "      <td>-1.084738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.774930</td>\n",
       "      <td>0.242207</td>\n",
       "      <td>-2.169435</td>\n",
       "      <td>0.957587</td>\n",
       "      <td>1.962123</td>\n",
       "      <td>-6.537835</td>\n",
       "      <td>-0.093013</td>\n",
       "      <td>10.746747</td>\n",
       "      <td>-1.772821</td>\n",
       "      <td>1.569651</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.440256</td>\n",
       "      <td>2.888166</td>\n",
       "      <td>-1.136555</td>\n",
       "      <td>-1.865950</td>\n",
       "      <td>-1.182768</td>\n",
       "      <td>-2.160472</td>\n",
       "      <td>-6.163668</td>\n",
       "      <td>-1.540079</td>\n",
       "      <td>-6.854830</td>\n",
       "      <td>-2.516365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.825367</td>\n",
       "      <td>-3.512079</td>\n",
       "      <td>-3.411305</td>\n",
       "      <td>-3.422770</td>\n",
       "      <td>-2.032776</td>\n",
       "      <td>-9.414887</td>\n",
       "      <td>-6.045628</td>\n",
       "      <td>-3.327482</td>\n",
       "      <td>-3.349400</td>\n",
       "      <td>-1.996181</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.239841</td>\n",
       "      <td>-0.643408</td>\n",
       "      <td>-4.734625</td>\n",
       "      <td>-3.649913</td>\n",
       "      <td>-3.510336</td>\n",
       "      <td>-3.900307</td>\n",
       "      <td>-5.759856</td>\n",
       "      <td>-3.000462</td>\n",
       "      <td>-5.776918</td>\n",
       "      <td>-4.311537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.901577</td>\n",
       "      <td>-3.821093</td>\n",
       "      <td>-4.683027</td>\n",
       "      <td>-2.989506</td>\n",
       "      <td>-1.766593</td>\n",
       "      <td>-5.948125</td>\n",
       "      <td>-5.973610</td>\n",
       "      <td>-0.410082</td>\n",
       "      <td>-4.782912</td>\n",
       "      <td>-3.061295</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.980726</td>\n",
       "      <td>-1.145141</td>\n",
       "      <td>-3.394280</td>\n",
       "      <td>-3.888476</td>\n",
       "      <td>-2.341227</td>\n",
       "      <td>-4.294225</td>\n",
       "      <td>-5.394603</td>\n",
       "      <td>-3.269752</td>\n",
       "      <td>-8.546793</td>\n",
       "      <td>-4.099878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>-2.661973</td>\n",
       "      <td>-2.209362</td>\n",
       "      <td>-6.268367</td>\n",
       "      <td>0.859524</td>\n",
       "      <td>-0.513444</td>\n",
       "      <td>0.643707</td>\n",
       "      <td>-3.673237</td>\n",
       "      <td>-4.044534</td>\n",
       "      <td>-6.381132</td>\n",
       "      <td>-5.128937</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.168150</td>\n",
       "      <td>-0.373650</td>\n",
       "      <td>-1.336461</td>\n",
       "      <td>-3.617270</td>\n",
       "      <td>-3.557010</td>\n",
       "      <td>-4.144451</td>\n",
       "      <td>-1.432600</td>\n",
       "      <td>-2.071712</td>\n",
       "      <td>-4.544137</td>\n",
       "      <td>-3.356391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>-4.707115</td>\n",
       "      <td>-4.023519</td>\n",
       "      <td>-6.189471</td>\n",
       "      <td>-3.194440</td>\n",
       "      <td>-2.585716</td>\n",
       "      <td>-6.921193</td>\n",
       "      <td>-5.987907</td>\n",
       "      <td>-5.147150</td>\n",
       "      <td>-5.178342</td>\n",
       "      <td>-4.201793</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.470380</td>\n",
       "      <td>-1.893575</td>\n",
       "      <td>-2.263472</td>\n",
       "      <td>-4.268863</td>\n",
       "      <td>-3.806721</td>\n",
       "      <td>-5.458024</td>\n",
       "      <td>-5.395541</td>\n",
       "      <td>-3.586476</td>\n",
       "      <td>-7.234397</td>\n",
       "      <td>-4.791286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>-5.750512</td>\n",
       "      <td>-5.383486</td>\n",
       "      <td>-7.624173</td>\n",
       "      <td>-3.593961</td>\n",
       "      <td>-4.158639</td>\n",
       "      <td>-2.654644</td>\n",
       "      <td>-5.899866</td>\n",
       "      <td>-4.798430</td>\n",
       "      <td>-5.140665</td>\n",
       "      <td>-6.071514</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.663612</td>\n",
       "      <td>-2.523735</td>\n",
       "      <td>-1.689437</td>\n",
       "      <td>-4.449357</td>\n",
       "      <td>-4.587792</td>\n",
       "      <td>-5.864083</td>\n",
       "      <td>-4.658562</td>\n",
       "      <td>-4.053533</td>\n",
       "      <td>-8.858572</td>\n",
       "      <td>-4.676476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>-5.409941</td>\n",
       "      <td>-3.927712</td>\n",
       "      <td>-9.223672</td>\n",
       "      <td>-0.083357</td>\n",
       "      <td>-1.178472</td>\n",
       "      <td>-0.297988</td>\n",
       "      <td>-4.128627</td>\n",
       "      <td>4.525619</td>\n",
       "      <td>-9.103663</td>\n",
       "      <td>-5.298180</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.953674</td>\n",
       "      <td>-1.227330</td>\n",
       "      <td>0.991064</td>\n",
       "      <td>-3.654199</td>\n",
       "      <td>-5.241496</td>\n",
       "      <td>-5.176800</td>\n",
       "      <td>-3.323158</td>\n",
       "      <td>-2.900181</td>\n",
       "      <td>-6.058720</td>\n",
       "      <td>-4.504592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>-5.154389</td>\n",
       "      <td>-3.671170</td>\n",
       "      <td>-6.224911</td>\n",
       "      <td>-2.732297</td>\n",
       "      <td>-2.413994</td>\n",
       "      <td>-3.820012</td>\n",
       "      <td>-6.211867</td>\n",
       "      <td>-1.139744</td>\n",
       "      <td>-6.462436</td>\n",
       "      <td>-4.784895</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.406441</td>\n",
       "      <td>-2.065371</td>\n",
       "      <td>0.092785</td>\n",
       "      <td>-4.099862</td>\n",
       "      <td>-3.356080</td>\n",
       "      <td>-4.658442</td>\n",
       "      <td>-4.446765</td>\n",
       "      <td>-3.665572</td>\n",
       "      <td>-9.572459</td>\n",
       "      <td>-4.190299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499 rows × 194 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          414       599       474       448       274       610        68  \\\n",
       "0   -4.115953 -2.882551 -4.728258 -2.525126 -2.760124 -9.337418 -4.686259   \n",
       "1    0.177609 -1.555334 -0.151824  2.140778  6.779421  4.791630 -0.184555   \n",
       "2   -1.774930  0.242207 -2.169435  0.957587  1.962123 -6.537835 -0.093013   \n",
       "3   -4.825367 -3.512079 -3.411305 -3.422770 -2.032776 -9.414887 -6.045628   \n",
       "4   -4.901577 -3.821093 -4.683027 -2.989506 -1.766593 -5.948125 -5.973610   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "494 -2.661973 -2.209362 -6.268367  0.859524 -0.513444  0.643707 -3.673237   \n",
       "495 -4.707115 -4.023519 -6.189471 -3.194440 -2.585716 -6.921193 -5.987907   \n",
       "496 -5.750512 -5.383486 -7.624173 -3.593961 -4.158639 -2.654644 -5.899866   \n",
       "497 -5.409941 -3.927712 -9.223672 -0.083357 -1.178472 -0.297988 -4.128627   \n",
       "498 -5.154389 -3.671170 -6.224911 -2.732297 -2.413994 -3.820012 -6.211867   \n",
       "\n",
       "           380       606       288  ...        15        27       184  \\\n",
       "0    -2.190597 -4.136896 -2.567320  ... -4.885970 -1.085753 -2.794318   \n",
       "1     6.122128 -2.806886  1.566354  ... -2.710675  2.648918  1.545335   \n",
       "2    10.746747 -1.772821  1.569651  ... -2.440256  2.888166 -1.136555   \n",
       "3    -3.327482 -3.349400 -1.996181  ... -5.239841 -0.643408 -4.734625   \n",
       "4    -0.410082 -4.782912 -3.061295  ... -4.980726 -1.145141 -3.394280   \n",
       "..         ...       ...       ...  ...       ...       ...       ...   \n",
       "494  -4.044534 -6.381132 -5.128937  ... -3.168150 -0.373650 -1.336461   \n",
       "495  -5.147150 -5.178342 -4.201793  ... -5.470380 -1.893575 -2.263472   \n",
       "496  -4.798430 -5.140665 -6.071514  ... -4.663612 -2.523735 -1.689437   \n",
       "497   4.525619 -9.103663 -5.298180  ... -3.953674 -1.227330  0.991064   \n",
       "498  -1.139744 -6.462436 -4.784895  ... -4.406441 -2.065371  0.092785   \n",
       "\n",
       "          376       377       524        52       268       369       314  \n",
       "0   -3.953106 -3.176873 -3.743190 -5.550285 -2.723604 -6.304630 -3.653785  \n",
       "1   -0.728034 -2.532983 -1.035239 -0.075564 -0.515175 -2.241114 -1.084738  \n",
       "2   -1.865950 -1.182768 -2.160472 -6.163668 -1.540079 -6.854830 -2.516365  \n",
       "3   -3.649913 -3.510336 -3.900307 -5.759856 -3.000462 -5.776918 -4.311537  \n",
       "4   -3.888476 -2.341227 -4.294225 -5.394603 -3.269752 -8.546793 -4.099878  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "494 -3.617270 -3.557010 -4.144451 -1.432600 -2.071712 -4.544137 -3.356391  \n",
       "495 -4.268863 -3.806721 -5.458024 -5.395541 -3.586476 -7.234397 -4.791286  \n",
       "496 -4.449357 -4.587792 -5.864083 -4.658562 -4.053533 -8.858572 -4.676476  \n",
       "497 -3.654199 -5.241496 -5.176800 -3.323158 -2.900181 -6.058720 -4.504592  \n",
       "498 -4.099862 -3.356080 -4.658442 -4.446765 -3.665572 -9.572459 -4.190299  \n",
       "\n",
       "[499 rows x 194 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39898ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for uid in subj_idx:\n",
    "    pred_vals = []\n",
    "\n",
    "    dim = len(selected.columns)\n",
    "    sim_vec = sim.loc[:,uid].to_numpy().reshape((dim, 1)) # shape (40,1), dot積を計算できるようにする\n",
    "\n",
    "    for iid in range(7000):\n",
    "        rate_vec = test_continuous_df\n",
    "        rate_vec = rate_vec.loc[iid,:].to_numpy().reshape((1, dim))#movieidごとの各userの予測値, shape (1, 40)\n",
    "        if sim_vec.sum() == 0:\n",
    "            score = np.array([0])\n",
    "            print(f'sim_vec.sum() = 0!!!')\n",
    "        else: \n",
    "#             print(f'np.dot(rate_vec, sim_vec): {np.dot(rate_vec, sim_vec)[0][0]}')#1行40列と40行1列の積→1行1列の行列ができる\n",
    "            if np.dot(rate_vec, sim_vec)[0][0]==0:\n",
    "                print(f'sim_vec: {sim_vec}')\n",
    "              # print(f'rate_vec: {rate_vec}')\n",
    "#             print(f'mean[{uid}]: {mean[uid]}')\n",
    "#             print(f'sim_vec.sum(): {sim_vec.sum()}')\n",
    "            score = (np.dot(rate_vec, sim_vec)/(sim_vec.sum()))[0][0]#main # score = self.mean[uid] + np.dot(rate_vec, sim_vec)/(sim_vec.sum())\n",
    "#             print(f'score:{score}')\n",
    "        pred_vals.append(score)\n",
    "    df[uid] = pred_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c023b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>414</th>\n",
       "      <th>599</th>\n",
       "      <th>474</th>\n",
       "      <th>448</th>\n",
       "      <th>274</th>\n",
       "      <th>610</th>\n",
       "      <th>68</th>\n",
       "      <th>380</th>\n",
       "      <th>606</th>\n",
       "      <th>288</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>27</th>\n",
       "      <th>184</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>524</th>\n",
       "      <th>52</th>\n",
       "      <th>268</th>\n",
       "      <th>369</th>\n",
       "      <th>314</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.830133</td>\n",
       "      <td>-3.243494</td>\n",
       "      <td>-2.485519</td>\n",
       "      <td>-2.454647</td>\n",
       "      <td>-3.359804</td>\n",
       "      <td>-7.863664</td>\n",
       "      <td>-3.415399</td>\n",
       "      <td>-2.646676</td>\n",
       "      <td>-2.700992</td>\n",
       "      <td>-1.969645</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.383994</td>\n",
       "      <td>1.117738</td>\n",
       "      <td>0.174237</td>\n",
       "      <td>-3.424375</td>\n",
       "      <td>-1.637333</td>\n",
       "      <td>-3.254944</td>\n",
       "      <td>-3.526438</td>\n",
       "      <td>-1.675726</td>\n",
       "      <td>-8.844037</td>\n",
       "      <td>-1.571888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.832250</td>\n",
       "      <td>-4.423019</td>\n",
       "      <td>-5.252868</td>\n",
       "      <td>-2.231903</td>\n",
       "      <td>-3.779386</td>\n",
       "      <td>-5.236586</td>\n",
       "      <td>-4.672434</td>\n",
       "      <td>-4.295438</td>\n",
       "      <td>-5.631115</td>\n",
       "      <td>-4.123087</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.248902</td>\n",
       "      <td>-2.372265</td>\n",
       "      <td>-2.559961</td>\n",
       "      <td>-4.134014</td>\n",
       "      <td>-3.464284</td>\n",
       "      <td>-5.654548</td>\n",
       "      <td>-4.632083</td>\n",
       "      <td>-3.526494</td>\n",
       "      <td>-6.970410</td>\n",
       "      <td>-4.034983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.528484</td>\n",
       "      <td>-4.082127</td>\n",
       "      <td>-6.306951</td>\n",
       "      <td>-5.705662</td>\n",
       "      <td>-4.633645</td>\n",
       "      <td>-3.931232</td>\n",
       "      <td>-5.775435</td>\n",
       "      <td>-6.804845</td>\n",
       "      <td>-4.065035</td>\n",
       "      <td>-5.536053</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.077084</td>\n",
       "      <td>-3.679231</td>\n",
       "      <td>-2.600484</td>\n",
       "      <td>-4.225941</td>\n",
       "      <td>-3.835179</td>\n",
       "      <td>-5.451268</td>\n",
       "      <td>-5.449390</td>\n",
       "      <td>-3.979099</td>\n",
       "      <td>-9.689861</td>\n",
       "      <td>-4.528767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.823083</td>\n",
       "      <td>-3.439209</td>\n",
       "      <td>-6.800572</td>\n",
       "      <td>-1.822206</td>\n",
       "      <td>-1.864185</td>\n",
       "      <td>-8.066014</td>\n",
       "      <td>-4.193544</td>\n",
       "      <td>-7.859553</td>\n",
       "      <td>-5.893215</td>\n",
       "      <td>-4.432599</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.383513</td>\n",
       "      <td>-2.825325</td>\n",
       "      <td>-3.170189</td>\n",
       "      <td>-4.347135</td>\n",
       "      <td>-4.532516</td>\n",
       "      <td>-5.662442</td>\n",
       "      <td>-4.114850</td>\n",
       "      <td>-3.301274</td>\n",
       "      <td>-6.985278</td>\n",
       "      <td>-3.019661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.128581</td>\n",
       "      <td>-3.549844</td>\n",
       "      <td>-5.076648</td>\n",
       "      <td>-2.296556</td>\n",
       "      <td>-3.601963</td>\n",
       "      <td>-6.239752</td>\n",
       "      <td>-5.922780</td>\n",
       "      <td>-5.100939</td>\n",
       "      <td>-6.484184</td>\n",
       "      <td>-4.018108</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.028192</td>\n",
       "      <td>-1.300548</td>\n",
       "      <td>-3.740407</td>\n",
       "      <td>-3.874563</td>\n",
       "      <td>-3.022250</td>\n",
       "      <td>-4.187817</td>\n",
       "      <td>-5.043244</td>\n",
       "      <td>-2.720942</td>\n",
       "      <td>-6.005246</td>\n",
       "      <td>-3.755231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>-5.580066</td>\n",
       "      <td>-6.710597</td>\n",
       "      <td>-5.941798</td>\n",
       "      <td>-4.570248</td>\n",
       "      <td>-2.989096</td>\n",
       "      <td>-3.431279</td>\n",
       "      <td>-4.590853</td>\n",
       "      <td>-6.717676</td>\n",
       "      <td>-4.183838</td>\n",
       "      <td>-4.793321</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.877735</td>\n",
       "      <td>-2.088717</td>\n",
       "      <td>-3.273232</td>\n",
       "      <td>-4.352569</td>\n",
       "      <td>-5.120519</td>\n",
       "      <td>-6.358463</td>\n",
       "      <td>-4.233028</td>\n",
       "      <td>-4.217791</td>\n",
       "      <td>-9.804720</td>\n",
       "      <td>-5.608462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>-5.439671</td>\n",
       "      <td>-4.736877</td>\n",
       "      <td>-7.682322</td>\n",
       "      <td>-4.039812</td>\n",
       "      <td>-3.936236</td>\n",
       "      <td>-5.369798</td>\n",
       "      <td>-4.531440</td>\n",
       "      <td>-6.904364</td>\n",
       "      <td>-6.192249</td>\n",
       "      <td>-6.139895</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.097141</td>\n",
       "      <td>-3.766301</td>\n",
       "      <td>-0.468694</td>\n",
       "      <td>-4.424210</td>\n",
       "      <td>-4.610067</td>\n",
       "      <td>-5.284590</td>\n",
       "      <td>-5.264586</td>\n",
       "      <td>-3.895189</td>\n",
       "      <td>-8.787097</td>\n",
       "      <td>-4.468648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>-4.828237</td>\n",
       "      <td>-3.273436</td>\n",
       "      <td>-5.619606</td>\n",
       "      <td>-1.024993</td>\n",
       "      <td>-1.749808</td>\n",
       "      <td>-8.865098</td>\n",
       "      <td>-4.697419</td>\n",
       "      <td>-2.242884</td>\n",
       "      <td>-6.514058</td>\n",
       "      <td>-3.324684</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.729492</td>\n",
       "      <td>-0.714654</td>\n",
       "      <td>-4.547103</td>\n",
       "      <td>-3.675325</td>\n",
       "      <td>-3.762526</td>\n",
       "      <td>-5.091745</td>\n",
       "      <td>-5.184002</td>\n",
       "      <td>-2.488785</td>\n",
       "      <td>-5.743479</td>\n",
       "      <td>-4.288840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6998</th>\n",
       "      <td>-5.254075</td>\n",
       "      <td>-4.132425</td>\n",
       "      <td>-6.141393</td>\n",
       "      <td>-3.762031</td>\n",
       "      <td>-2.311413</td>\n",
       "      <td>-5.190947</td>\n",
       "      <td>-6.281285</td>\n",
       "      <td>1.481875</td>\n",
       "      <td>-5.549736</td>\n",
       "      <td>-3.448219</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.187454</td>\n",
       "      <td>-0.499701</td>\n",
       "      <td>-1.336251</td>\n",
       "      <td>-3.808911</td>\n",
       "      <td>-2.620901</td>\n",
       "      <td>-5.122132</td>\n",
       "      <td>-4.843269</td>\n",
       "      <td>-4.261615</td>\n",
       "      <td>-10.290594</td>\n",
       "      <td>-4.631672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>-6.043765</td>\n",
       "      <td>-5.090617</td>\n",
       "      <td>-7.537493</td>\n",
       "      <td>-1.100033</td>\n",
       "      <td>-5.276970</td>\n",
       "      <td>-3.632580</td>\n",
       "      <td>-5.132684</td>\n",
       "      <td>-5.866147</td>\n",
       "      <td>-5.202042</td>\n",
       "      <td>-6.126310</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.030814</td>\n",
       "      <td>-2.997346</td>\n",
       "      <td>0.414013</td>\n",
       "      <td>-3.534237</td>\n",
       "      <td>-3.728738</td>\n",
       "      <td>-5.553586</td>\n",
       "      <td>-4.113480</td>\n",
       "      <td>-3.177543</td>\n",
       "      <td>-9.415884</td>\n",
       "      <td>-5.199031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows × 194 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           414       599       474       448       274       610        68  \\\n",
       "0    -3.830133 -3.243494 -2.485519 -2.454647 -3.359804 -7.863664 -3.415399   \n",
       "1    -4.832250 -4.423019 -5.252868 -2.231903 -3.779386 -5.236586 -4.672434   \n",
       "2    -4.528484 -4.082127 -6.306951 -5.705662 -4.633645 -3.931232 -5.775435   \n",
       "3    -4.823083 -3.439209 -6.800572 -1.822206 -1.864185 -8.066014 -4.193544   \n",
       "4    -5.128581 -3.549844 -5.076648 -2.296556 -3.601963 -6.239752 -5.922780   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6995 -5.580066 -6.710597 -5.941798 -4.570248 -2.989096 -3.431279 -4.590853   \n",
       "6996 -5.439671 -4.736877 -7.682322 -4.039812 -3.936236 -5.369798 -4.531440   \n",
       "6997 -4.828237 -3.273436 -5.619606 -1.024993 -1.749808 -8.865098 -4.697419   \n",
       "6998 -5.254075 -4.132425 -6.141393 -3.762031 -2.311413 -5.190947 -6.281285   \n",
       "6999 -6.043765 -5.090617 -7.537493 -1.100033 -5.276970 -3.632580 -5.132684   \n",
       "\n",
       "           380       606       288  ...        15        27       184  \\\n",
       "0    -2.646676 -2.700992 -1.969645  ... -3.383994  1.117738  0.174237   \n",
       "1    -4.295438 -5.631115 -4.123087  ... -4.248902 -2.372265 -2.559961   \n",
       "2    -6.804845 -4.065035 -5.536053  ... -4.077084 -3.679231 -2.600484   \n",
       "3    -7.859553 -5.893215 -4.432599  ... -5.383513 -2.825325 -3.170189   \n",
       "4    -5.100939 -6.484184 -4.018108  ... -5.028192 -1.300548 -3.740407   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "6995 -6.717676 -4.183838 -4.793321  ... -4.877735 -2.088717 -3.273232   \n",
       "6996 -6.904364 -6.192249 -6.139895  ... -5.097141 -3.766301 -0.468694   \n",
       "6997 -2.242884 -6.514058 -3.324684  ... -4.729492 -0.714654 -4.547103   \n",
       "6998  1.481875 -5.549736 -3.448219  ... -4.187454 -0.499701 -1.336251   \n",
       "6999 -5.866147 -5.202042 -6.126310  ... -5.030814 -2.997346  0.414013   \n",
       "\n",
       "           376       377       524        52       268        369       314  \n",
       "0    -3.424375 -1.637333 -3.254944 -3.526438 -1.675726  -8.844037 -1.571888  \n",
       "1    -4.134014 -3.464284 -5.654548 -4.632083 -3.526494  -6.970410 -4.034983  \n",
       "2    -4.225941 -3.835179 -5.451268 -5.449390 -3.979099  -9.689861 -4.528767  \n",
       "3    -4.347135 -4.532516 -5.662442 -4.114850 -3.301274  -6.985278 -3.019661  \n",
       "4    -3.874563 -3.022250 -4.187817 -5.043244 -2.720942  -6.005246 -3.755231  \n",
       "...        ...       ...       ...       ...       ...        ...       ...  \n",
       "6995 -4.352569 -5.120519 -6.358463 -4.233028 -4.217791  -9.804720 -5.608462  \n",
       "6996 -4.424210 -4.610067 -5.284590 -5.264586 -3.895189  -8.787097 -4.468648  \n",
       "6997 -3.675325 -3.762526 -5.091745 -5.184002 -2.488785  -5.743479 -4.288840  \n",
       "6998 -3.808911 -2.620901 -5.122132 -4.843269 -4.261615 -10.290594 -4.631672  \n",
       "6999 -3.534237 -3.728738 -5.553586 -4.113480 -3.177543  -9.415884 -5.199031  \n",
       "\n",
       "[7000 rows x 194 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11546661",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
      "/tmp/ipykernel_169/3204309238.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>414</th>\n",
       "      <th>599</th>\n",
       "      <th>474</th>\n",
       "      <th>448</th>\n",
       "      <th>274</th>\n",
       "      <th>610</th>\n",
       "      <th>68</th>\n",
       "      <th>380</th>\n",
       "      <th>606</th>\n",
       "      <th>288</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>27</th>\n",
       "      <th>184</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>524</th>\n",
       "      <th>52</th>\n",
       "      <th>268</th>\n",
       "      <th>369</th>\n",
       "      <th>314</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.299327</td>\n",
       "      <td>0.339818</td>\n",
       "      <td>0.589328</td>\n",
       "      <td>0.404224</td>\n",
       "      <td>0.437202</td>\n",
       "      <td>0.184770</td>\n",
       "      <td>0.288171</td>\n",
       "      <td>0.474309</td>\n",
       "      <td>0.536069</td>\n",
       "      <td>0.499051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334060</td>\n",
       "      <td>0.666520</td>\n",
       "      <td>0.533044</td>\n",
       "      <td>0.229935</td>\n",
       "      <td>0.612051</td>\n",
       "      <td>0.342181</td>\n",
       "      <td>0.314065</td>\n",
       "      <td>0.530737</td>\n",
       "      <td>0.303610</td>\n",
       "      <td>0.499843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.204198</td>\n",
       "      <td>0.201362</td>\n",
       "      <td>0.385130</td>\n",
       "      <td>0.422378</td>\n",
       "      <td>0.413912</td>\n",
       "      <td>0.314410</td>\n",
       "      <td>0.197928</td>\n",
       "      <td>0.413892</td>\n",
       "      <td>0.333056</td>\n",
       "      <td>0.305288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245961</td>\n",
       "      <td>0.327529</td>\n",
       "      <td>0.327160</td>\n",
       "      <td>0.140338</td>\n",
       "      <td>0.344126</td>\n",
       "      <td>0.160072</td>\n",
       "      <td>0.213843</td>\n",
       "      <td>0.311288</td>\n",
       "      <td>0.376825</td>\n",
       "      <td>0.242442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.233034</td>\n",
       "      <td>0.241377</td>\n",
       "      <td>0.307352</td>\n",
       "      <td>0.139254</td>\n",
       "      <td>0.366494</td>\n",
       "      <td>0.378827</td>\n",
       "      <td>0.118743</td>\n",
       "      <td>0.321938</td>\n",
       "      <td>0.441561</td>\n",
       "      <td>0.178152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.263462</td>\n",
       "      <td>0.200580</td>\n",
       "      <td>0.324108</td>\n",
       "      <td>0.128732</td>\n",
       "      <td>0.289734</td>\n",
       "      <td>0.175499</td>\n",
       "      <td>0.139757</td>\n",
       "      <td>0.257622</td>\n",
       "      <td>0.270557</td>\n",
       "      <td>0.190840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.205068</td>\n",
       "      <td>0.316844</td>\n",
       "      <td>0.270928</td>\n",
       "      <td>0.455770</td>\n",
       "      <td>0.520219</td>\n",
       "      <td>0.174785</td>\n",
       "      <td>0.232307</td>\n",
       "      <td>0.283290</td>\n",
       "      <td>0.314896</td>\n",
       "      <td>0.277439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130391</td>\n",
       "      <td>0.283522</td>\n",
       "      <td>0.281210</td>\n",
       "      <td>0.113431</td>\n",
       "      <td>0.187469</td>\n",
       "      <td>0.159473</td>\n",
       "      <td>0.260728</td>\n",
       "      <td>0.337993</td>\n",
       "      <td>0.376244</td>\n",
       "      <td>0.348546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.176068</td>\n",
       "      <td>0.303858</td>\n",
       "      <td>0.398133</td>\n",
       "      <td>0.417109</td>\n",
       "      <td>0.423760</td>\n",
       "      <td>0.264906</td>\n",
       "      <td>0.108165</td>\n",
       "      <td>0.384376</td>\n",
       "      <td>0.273951</td>\n",
       "      <td>0.314734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166584</td>\n",
       "      <td>0.431627</td>\n",
       "      <td>0.238273</td>\n",
       "      <td>0.173096</td>\n",
       "      <td>0.408951</td>\n",
       "      <td>0.271384</td>\n",
       "      <td>0.176572</td>\n",
       "      <td>0.406804</td>\n",
       "      <td>0.414540</td>\n",
       "      <td>0.271677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>0.133210</td>\n",
       "      <td>-0.067161</td>\n",
       "      <td>0.334295</td>\n",
       "      <td>0.231794</td>\n",
       "      <td>0.457778</td>\n",
       "      <td>0.403498</td>\n",
       "      <td>0.203785</td>\n",
       "      <td>0.325132</td>\n",
       "      <td>0.433330</td>\n",
       "      <td>0.244982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181909</td>\n",
       "      <td>0.355070</td>\n",
       "      <td>0.273451</td>\n",
       "      <td>0.112745</td>\n",
       "      <td>0.101238</td>\n",
       "      <td>0.106651</td>\n",
       "      <td>0.250015</td>\n",
       "      <td>0.229320</td>\n",
       "      <td>0.266069</td>\n",
       "      <td>0.078009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>0.146537</td>\n",
       "      <td>0.164520</td>\n",
       "      <td>0.205865</td>\n",
       "      <td>0.275027</td>\n",
       "      <td>0.405205</td>\n",
       "      <td>0.307837</td>\n",
       "      <td>0.208050</td>\n",
       "      <td>0.318291</td>\n",
       "      <td>0.294177</td>\n",
       "      <td>0.123819</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159561</td>\n",
       "      <td>0.192123</td>\n",
       "      <td>0.484631</td>\n",
       "      <td>0.103699</td>\n",
       "      <td>0.176096</td>\n",
       "      <td>0.188149</td>\n",
       "      <td>0.156509</td>\n",
       "      <td>0.267571</td>\n",
       "      <td>0.305835</td>\n",
       "      <td>0.197123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>0.204579</td>\n",
       "      <td>0.336303</td>\n",
       "      <td>0.358069</td>\n",
       "      <td>0.520746</td>\n",
       "      <td>0.526568</td>\n",
       "      <td>0.135352</td>\n",
       "      <td>0.196134</td>\n",
       "      <td>0.489105</td>\n",
       "      <td>0.271881</td>\n",
       "      <td>0.377127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.197009</td>\n",
       "      <td>0.488536</td>\n",
       "      <td>0.177529</td>\n",
       "      <td>0.198251</td>\n",
       "      <td>0.300389</td>\n",
       "      <td>0.202784</td>\n",
       "      <td>0.163813</td>\n",
       "      <td>0.434331</td>\n",
       "      <td>0.424769</td>\n",
       "      <td>0.215913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6998</th>\n",
       "      <td>0.164155</td>\n",
       "      <td>0.235473</td>\n",
       "      <td>0.319568</td>\n",
       "      <td>0.297667</td>\n",
       "      <td>0.495395</td>\n",
       "      <td>0.316663</td>\n",
       "      <td>0.082428</td>\n",
       "      <td>0.625594</td>\n",
       "      <td>0.338694</td>\n",
       "      <td>0.366011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.252220</td>\n",
       "      <td>0.509415</td>\n",
       "      <td>0.419305</td>\n",
       "      <td>0.181385</td>\n",
       "      <td>0.467809</td>\n",
       "      <td>0.200478</td>\n",
       "      <td>0.194699</td>\n",
       "      <td>0.224123</td>\n",
       "      <td>0.247083</td>\n",
       "      <td>0.180086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>0.089192</td>\n",
       "      <td>0.122997</td>\n",
       "      <td>0.216552</td>\n",
       "      <td>0.514630</td>\n",
       "      <td>0.330785</td>\n",
       "      <td>0.393565</td>\n",
       "      <td>0.164886</td>\n",
       "      <td>0.356336</td>\n",
       "      <td>0.362784</td>\n",
       "      <td>0.125042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166317</td>\n",
       "      <td>0.266813</td>\n",
       "      <td>0.551099</td>\n",
       "      <td>0.216064</td>\n",
       "      <td>0.305344</td>\n",
       "      <td>0.167734</td>\n",
       "      <td>0.260852</td>\n",
       "      <td>0.352664</td>\n",
       "      <td>0.281264</td>\n",
       "      <td>0.120795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows × 194 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           414       599       474       448       274       610        68  \\\n",
       "0     0.299327  0.339818  0.589328  0.404224  0.437202  0.184770  0.288171   \n",
       "1     0.204198  0.201362  0.385130  0.422378  0.413912  0.314410  0.197928   \n",
       "2     0.233034  0.241377  0.307352  0.139254  0.366494  0.378827  0.118743   \n",
       "3     0.205068  0.316844  0.270928  0.455770  0.520219  0.174785  0.232307   \n",
       "4     0.176068  0.303858  0.398133  0.417109  0.423760  0.264906  0.108165   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6995  0.133210 -0.067161  0.334295  0.231794  0.457778  0.403498  0.203785   \n",
       "6996  0.146537  0.164520  0.205865  0.275027  0.405205  0.307837  0.208050   \n",
       "6997  0.204579  0.336303  0.358069  0.520746  0.526568  0.135352  0.196134   \n",
       "6998  0.164155  0.235473  0.319568  0.297667  0.495395  0.316663  0.082428   \n",
       "6999  0.089192  0.122997  0.216552  0.514630  0.330785  0.393565  0.164886   \n",
       "\n",
       "           380       606       288  ...        15        27       184  \\\n",
       "0     0.474309  0.536069  0.499051  ...  0.334060  0.666520  0.533044   \n",
       "1     0.413892  0.333056  0.305288  ...  0.245961  0.327529  0.327160   \n",
       "2     0.321938  0.441561  0.178152  ...  0.263462  0.200580  0.324108   \n",
       "3     0.283290  0.314896  0.277439  ...  0.130391  0.283522  0.281210   \n",
       "4     0.384376  0.273951  0.314734  ...  0.166584  0.431627  0.238273   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "6995  0.325132  0.433330  0.244982  ...  0.181909  0.355070  0.273451   \n",
       "6996  0.318291  0.294177  0.123819  ...  0.159561  0.192123  0.484631   \n",
       "6997  0.489105  0.271881  0.377127  ...  0.197009  0.488536  0.177529   \n",
       "6998  0.625594  0.338694  0.366011  ...  0.252220  0.509415  0.419305   \n",
       "6999  0.356336  0.362784  0.125042  ...  0.166317  0.266813  0.551099   \n",
       "\n",
       "           376       377       524        52       268       369       314  \n",
       "0     0.229935  0.612051  0.342181  0.314065  0.530737  0.303610  0.499843  \n",
       "1     0.140338  0.344126  0.160072  0.213843  0.311288  0.376825  0.242442  \n",
       "2     0.128732  0.289734  0.175499  0.139757  0.257622  0.270557  0.190840  \n",
       "3     0.113431  0.187469  0.159473  0.260728  0.337993  0.376244  0.348546  \n",
       "4     0.173096  0.408951  0.271384  0.176572  0.406804  0.414540  0.271677  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "6995  0.112745  0.101238  0.106651  0.250015  0.229320  0.266069  0.078009  \n",
       "6996  0.103699  0.176096  0.188149  0.156509  0.267571  0.305835  0.197123  \n",
       "6997  0.198251  0.300389  0.202784  0.163813  0.434331  0.424769  0.215913  \n",
       "6998  0.181385  0.467809  0.200478  0.194699  0.224123  0.247083  0.180086  \n",
       "6999  0.216064  0.305344  0.167734  0.260852  0.352664  0.281264  0.120795  \n",
       "\n",
       "[7000 rows x 194 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normed_output_valid = pd.DataFrame()\n",
    "normed_output = pd.DataFrame()\n",
    "\n",
    "for col in df_valid.columns:\n",
    "    min = df_valid[col].min()\n",
    "    max = df_valid[col].max()\n",
    "    if df_valid.loc[0, col] == '[0]':\n",
    "        print(col + 'pass')\n",
    "        pass\n",
    "    else:\n",
    "        normed_output_valid[col] = df_valid[col].apply(lambda x: (x - min) / (max - min))\n",
    "        normed_output[col] = df[col].apply(lambda x: (x - min) / (max - min))\n",
    "normed_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d739d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_output.to_csv(\"/home/grigriko/collaborative_filtering/regression_continuous/regression_score_0511.csv\")\n",
    "normed_output_valid.to_csv(\"/home/grigriko/collaborative_filtering/regression_continuous/regression_score_valid_0511.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e37d299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inherit the name of df from iANN, call the input df as pred_df\n",
    "# actually it also contains true values  \n",
    "def createPred_df_iANN(pred_matrix, true_matrix):\n",
    "    val_output = pd.DataFrame()\n",
    "    val_output['pred_vec'] = pred_matrix\n",
    "    val_output['test_vec'] = true_matrix\n",
    "    val_output = val_output.reset_index(drop=True)\n",
    "    return val_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e587c754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# J = sensitivity + specificity - 1\n",
    "# J + 1 = TP/(TP+FN) + TN/(TN+FP)\n",
    "\n",
    "def JstatsPlus1(var):\n",
    "  \"\"\"Based on the input of TP, FN, TN, FP, calculate Youden's J +1 \"\"\"\n",
    "  if (var['TP']+var['FN']) == 0 or (var['TN']+var['FP']) == 0:\n",
    "    return 'NaN'\n",
    "  else:\n",
    "    output = var['TP']/(var['TP']+var['FN']) + var['TN']/(var['TN']+var['FP']) \n",
    "    return round(output, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9c34ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut DF to half and set as validation \n",
    "\n",
    "def createPredDfByThreshold_iANN_YoudensJ(subj_idx, pred_df, threshold):\n",
    "  '''\n",
    "  Based on two columns of prediction and acutal value of each user, \n",
    "  apply multiple threshold and add columns that evaluate the result of prediction\n",
    "  Structure of output is as follows: \n",
    "    [pred_vec, true_vec, binarised result in th1, TN/TP/FP/FN in th1, th2, th2, th3...]  \n",
    "  '''\n",
    "  print(pred_df)\n",
    "#   save_path = SAVED_MODEL_DIR\n",
    "\n",
    "  # add columns by multiple thresholds that show the result of prediction in each of the 2000 records.  \n",
    "  pred = 0\n",
    "\n",
    "  def binarize(x):\n",
    "    if float(x) > float(threshold):\n",
    "      pred = int(1)\n",
    "    elif float(x) <= float(threshold):\n",
    "      pred = int(0)\n",
    "    return pred\n",
    "  pred_df[\"pred_th\"] = pred_df[\"pred_vec\"].apply(binarize)\n",
    "  pred_df[\"result_th\"] = ''\n",
    "  print(pred_df)\n",
    "\n",
    "  for i in range(pred_df.shape[0]):\n",
    "    if int(pred_df.loc[i, 'test_vec']) == 1:\n",
    "      if pred_df.loc[i, \"pred_th\"] == 1:\n",
    "        pred_df.loc[i, \"result_th\"] = 'TP'\n",
    "      elif pred_df.loc[i, \"pred_th\"] == 0:\n",
    "        pred_df.loc[i, \"result_th\"] = 'FN' \n",
    "    elif int(pred_df.loc[i, 'test_vec']) == 0:\n",
    "      if pred_df.loc[i, \"pred_th\"] == 1:\n",
    "        pred_df.loc[i, \"result_th\"] = 'FP'\n",
    "      elif pred_df.loc[i, \"pred_th\"] == 0:\n",
    "        pred_df.loc[i, \"result_th\"] = 'TN'\n",
    "  print(pred_df)\n",
    "  #  true negative: outcome where the model correctly predicts the negative class(actual result is negative)\n",
    "  #  false positive: outcome where the model incorrectly predicts the positive class(actual result is negative)\n",
    "  #  false negative: where a negative test result is wrong. \n",
    "    # You get a negative test result(pred=N), but you should have got a positive test result(true=P).\n",
    "#   pred_df.to_csv(save_path + '/pred_df_' + subj_idx + '.csv', index = False)\n",
    "\n",
    "  return pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bad1a7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def YoudensCalculator(pred_vec):\n",
    "    \n",
    "    import collections\n",
    "    counter = collections.Counter([i for i in pred_vec])\n",
    "    print(counter)\n",
    "    return JstatsPlus1(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa7c96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_th = pd.DataFrame()\n",
    "for idx in subj_idx:\n",
    "    th_list = np.percentile(normed_output_valid[idx], q=np.arange(1,100)*1)\n",
    "    th_list = pd.DataFrame(th_list)#ユーザーごとに求めた100分割thresholdを結合していく\n",
    "    df_th = pd.concat([df_th, th_list], axis=1)\n",
    "df_th.columns = subj_idx\n",
    "\n",
    "df_allall_yJ = pd.DataFrame()\n",
    "for idx in subj_idx:\n",
    "    df_all_yJ = pd.DataFrame()\n",
    "    th_list = df_th[idx]\n",
    "    pred_matrix = normed_output_valid[idx]\n",
    "    true_matrix = all_true_valid[idx]\n",
    "    val_output = createPred_df_iANN(pred_matrix, true_matrix)\n",
    "    youdensJ = []\n",
    "    id_list = []\n",
    "    for th in th_list:\n",
    "#         print(th)\n",
    "        pred_df = createPredDfByThreshold_iANN_YoudensJ(idx, val_output, th)\n",
    "#         print(pred_df)\n",
    "        J = YoudensCalculator(pred_df['result_th'])\n",
    "        youdensJ.append(J)\n",
    "        id_list.append(idx)\n",
    "    df_all_yJ['id'] = id_list\n",
    "    df_all_yJ['youdensJ'] = youdensJ\n",
    "    df_all_yJ['th'] = th_list\n",
    "    df_allall_yJ = pd.concat([df_allall_yJ, df_all_yJ])\n",
    "df_allall_yJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "36f05054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>youdensJ</th>\n",
       "      <th>th</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>414</td>\n",
       "      <td>1.0183</td>\n",
       "      <td>0.041341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>414</td>\n",
       "      <td>1.0124</td>\n",
       "      <td>0.064364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>414</td>\n",
       "      <td>1.0064</td>\n",
       "      <td>0.070028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>414</td>\n",
       "      <td>1.0086</td>\n",
       "      <td>0.080665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>414</td>\n",
       "      <td>1.0188</td>\n",
       "      <td>0.086108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>314</td>\n",
       "      <td>0.9496</td>\n",
       "      <td>0.396099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>314</td>\n",
       "      <td>0.9597</td>\n",
       "      <td>0.408406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>314</td>\n",
       "      <td>0.9698</td>\n",
       "      <td>0.444312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>314</td>\n",
       "      <td>0.9798</td>\n",
       "      <td>0.471793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>314</td>\n",
       "      <td>0.9899</td>\n",
       "      <td>0.546630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19206 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  youdensJ        th\n",
       "0   414    1.0183  0.041341\n",
       "1   414    1.0124  0.064364\n",
       "2   414    1.0064  0.070028\n",
       "3   414    1.0086  0.080665\n",
       "4   414    1.0188  0.086108\n",
       "..  ...       ...       ...\n",
       "94  314    0.9496  0.396099\n",
       "95  314    0.9597  0.408406\n",
       "96  314    0.9698  0.444312\n",
       "97  314    0.9798  0.471793\n",
       "98  314    0.9899  0.546630\n",
       "\n",
       "[19206 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_allall_yJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d18900cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id  youdensJ        th\n",
      "0      1    1.2604  0.255722\n",
      "1     10    1.3869  0.258180\n",
      "2    100    1.1540  0.179422\n",
      "3    103    1.2215  0.290186\n",
      "4    104    1.2788  0.294344\n",
      "..   ...       ...       ...\n",
      "189   82    1.1642  0.357366\n",
      "190   84    1.2986  0.253542\n",
      "191   89    1.3407  0.408774\n",
      "192   91    1.1829  0.182148\n",
      "193   95    1.1230  0.179803\n",
      "\n",
      "[194 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "grouped = df_allall_yJ.groupby('id')#ユーザーごとにgroupbyでまとめる\n",
    "df_maxyj = pd.DataFrame(grouped.youdensJ.max())#groupbyしたものからyoudensJが最大のものを取り出す。(このdfにはidとyoudensJしか含まれていない)\n",
    "df_maxyj = df_maxyj.merge(df_allall_yJ, how='inner', on=['id','youdensJ'])#id, youdensJのみではなくthの情報が欲しいのでもとのdfと内部結合して列を増やす\n",
    "df_maxyj = df_maxyj.drop_duplicates(subset = 'id')#念のためidごとの被りをなくす\n",
    "print(df_maxyj)\n",
    "id_list = df_maxyj['id']\n",
    "df_maxyj_sorted = df_maxyj.set_axis(id_list, axis=0)#行名をsubj_idxへ\n",
    "#     df_maxyj_sorted = df_maxyj_sorted.reindex(list(subj_idx.values), axis=0)\n",
    "df_maxyj_sorted = df_maxyj_sorted.reindex((subj_idx), axis=0)#順番を元のsubj_idxの順に戻す\n",
    "df_maxyj_sorted\n",
    "df_maxyj_sorted.to_csv(\"/home/grigriko/collaborative_filtering/regression_continuous/valid_best_youdensJ.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8504ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_maxyj = pd.read_csv(\"/home/grigriko/collaborative_filtering/regression_continuous/valid_best_youdensJ.csv\")\n",
    "df_test_yJ = pd.DataFrame()\n",
    "youdensJ = []\n",
    "th_list = []\n",
    "for idx in subj_idx:\n",
    "    th = df_maxyj.loc[df_maxyj['id']==int(idx)]['th'].values#train dataでのbest thresholdをとってきている\n",
    "#     print(th)\n",
    "    th_list.append(th)\n",
    "    pred_matrix = normed_output.loc[4000:, idx]#test data\n",
    "    true_matrix = all_true_test.loc[4000:, idx]\n",
    "    test_output = createPred_df_iANN(pred_matrix, true_matrix)\n",
    "    pred_df = createPredDfByThreshold_iANN_YoudensJ(idx, test_output, th)\n",
    "    J = YoudensCalculator(pred_df['result_th'])#上の4つを数えてyoudensJを計算\n",
    "    youdensJ.append(J)\n",
    "df_test_yJ['id'] = subj_idx\n",
    "df_test_yJ['youdensJ'] = youdensJ\n",
    "df_test_yJ['th_list'] = th_list\n",
    "df_test_yJ.to_csv(\"/home/grigriko/collaborative_filtering/regression_continuous/test_youdensJ4k-.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "90000ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_yJ.to_csv(\"/home/grigriko/collaborative_filtering/regression_continuous/test_youdensJ.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4fbb6f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>youdensJ</th>\n",
       "      <th>th_list</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>414</td>\n",
       "      <td>1.0146</td>\n",
       "      <td>[0.242274958576819]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>599</td>\n",
       "      <td>1.0638</td>\n",
       "      <td>[0.1714964217562916]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>474</td>\n",
       "      <td>1.1520</td>\n",
       "      <td>[0.419986502287839]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>448</td>\n",
       "      <td>1.1141</td>\n",
       "      <td>[0.4382653529086875]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>274</td>\n",
       "      <td>1.1487</td>\n",
       "      <td>[0.5268082107057969]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>524</td>\n",
       "      <td>0.8890</td>\n",
       "      <td>[0.3568672432355677]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>1.2674</td>\n",
       "      <td>[0.3229591587106565]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>268</td>\n",
       "      <td>1.1713</td>\n",
       "      <td>[0.3810805349854962]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>369</td>\n",
       "      <td>1.2170</td>\n",
       "      <td>[0.468995737063626]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>314</td>\n",
       "      <td>0.8186</td>\n",
       "      <td>[0.3084457555600773]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  youdensJ               th_list\n",
       "userId                                     \n",
       "414     414    1.0146   [0.242274958576819]\n",
       "599     599    1.0638  [0.1714964217562916]\n",
       "474     474    1.1520   [0.419986502287839]\n",
       "448     448    1.1141  [0.4382653529086875]\n",
       "274     274    1.1487  [0.5268082107057969]\n",
       "...     ...       ...                   ...\n",
       "524     524    0.8890  [0.3568672432355677]\n",
       "52       52    1.2674  [0.3229591587106565]\n",
       "268     268    1.1713  [0.3810805349854962]\n",
       "369     369    1.2170   [0.468995737063626]\n",
       "314     314    0.8186  [0.3084457555600773]\n",
       "\n",
       "[194 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_yJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2b6ef3e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>iANN_selected3</th>\n",
       "      <th>selected3_2001-2500</th>\n",
       "      <th>selected3_continuous</th>\n",
       "      <th>iANN_selected5</th>\n",
       "      <th>selected5_2001-2500</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>414.0</td>\n",
       "      <td>1.0110</td>\n",
       "      <td>1.0246</td>\n",
       "      <td>1.0146</td>\n",
       "      <td>1.0168</td>\n",
       "      <td>1.0159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>599.0</td>\n",
       "      <td>0.9949</td>\n",
       "      <td>1.0502</td>\n",
       "      <td>1.0638</td>\n",
       "      <td>1.0271</td>\n",
       "      <td>1.0198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>474.0</td>\n",
       "      <td>1.1065</td>\n",
       "      <td>1.1111</td>\n",
       "      <td>1.1520</td>\n",
       "      <td>1.0889</td>\n",
       "      <td>1.1461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>448.0</td>\n",
       "      <td>1.0699</td>\n",
       "      <td>1.0701</td>\n",
       "      <td>1.1141</td>\n",
       "      <td>1.0288</td>\n",
       "      <td>1.1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>274.0</td>\n",
       "      <td>1.0286</td>\n",
       "      <td>1.1317</td>\n",
       "      <td>1.1487</td>\n",
       "      <td>1.0743</td>\n",
       "      <td>1.1059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>524.0</td>\n",
       "      <td>0.9647</td>\n",
       "      <td>1.7461</td>\n",
       "      <td>0.8890</td>\n",
       "      <td>0.9573</td>\n",
       "      <td>0.9504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52.0</td>\n",
       "      <td>0.7416</td>\n",
       "      <td>1.1846</td>\n",
       "      <td>1.2674</td>\n",
       "      <td>1.0948</td>\n",
       "      <td>1.3106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>268.0</td>\n",
       "      <td>1.1552</td>\n",
       "      <td>1.0704</td>\n",
       "      <td>1.1713</td>\n",
       "      <td>1.1804</td>\n",
       "      <td>1.2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>369.0</td>\n",
       "      <td>1.0140</td>\n",
       "      <td>1.1827</td>\n",
       "      <td>1.2170</td>\n",
       "      <td>1.1720</td>\n",
       "      <td>1.0193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>314.0</td>\n",
       "      <td>1.0659</td>\n",
       "      <td>0.9347</td>\n",
       "      <td>0.8186</td>\n",
       "      <td>0.8695</td>\n",
       "      <td>1.0269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  iANN_selected3  selected3_2001-2500  selected3_continuous  \\\n",
       "userId                                                                       \n",
       "414       414.0          1.0110               1.0246                1.0146   \n",
       "599       599.0          0.9949               1.0502                1.0638   \n",
       "474       474.0          1.1065               1.1111                1.1520   \n",
       "448       448.0          1.0699               1.0701                1.1141   \n",
       "274       274.0          1.0286               1.1317                1.1487   \n",
       "...         ...             ...                  ...                   ...   \n",
       "524       524.0          0.9647               1.7461                0.8890   \n",
       "52         52.0          0.7416               1.1846                1.2674   \n",
       "268       268.0          1.1552               1.0704                1.1713   \n",
       "369       369.0          1.0140               1.1827                1.2170   \n",
       "314       314.0          1.0659               0.9347                0.8186   \n",
       "\n",
       "        iANN_selected5  selected5_2001-2500  \n",
       "userId                                       \n",
       "414             1.0168               1.0159  \n",
       "599             1.0271               1.0198  \n",
       "474             1.0889               1.1461  \n",
       "448             1.0288               1.1004  \n",
       "274             1.0743               1.1059  \n",
       "...                ...                  ...  \n",
       "524             0.9573               0.9504  \n",
       "52              1.0948               1.3106  \n",
       "268             1.1804               1.2007  \n",
       "369             1.1720               1.0193  \n",
       "314             0.8695               1.0269  \n",
       "\n",
       "[194 rows x 6 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare = pd.read_csv(\"/home/grigriko/collaborative_filtering/selected_seed5/compare_youdensJ.csv\")\n",
    "compare = compare.drop(['10fold', 'iANN', 'valid2001-3000', 'valid2001-2500'], axis=1)\n",
    "compare.index = subj_idx\n",
    "compare.insert(loc=3, column='selected3_continuous', value=df_test_yJ['youdensJ'])\n",
    "compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6a6a9236",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare.to_csv(\"/home/grigriko/collaborative_filtering/regression_continuous/compare_youdensJ.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "02588656",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = pd.DataFrame()\n",
    "corr_list = []\n",
    "for idx in subj_idx:\n",
    "    co = normed_output.loc[6000:7000, idx].corr(all_true_test.loc[6000:7000, idx])\n",
    "    corr_list.append(co)\n",
    "\n",
    "corr_df['id'] = subj_idx\n",
    "corr_df['corr'] = corr_list\n",
    "corr_df.to_csv(\"/home/grigriko/collaborative_filtering/regression_continuous/corr_df6k-7k.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
